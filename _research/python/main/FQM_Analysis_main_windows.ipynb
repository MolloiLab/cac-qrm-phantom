{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "913d1281",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydicom\n",
      "  Downloading pydicom-2.2.2-py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.0 MB 18.5 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: pydicom\n",
      "Successfully installed pydicom-2.2.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pydicom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5517a0a6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting opencv-python\n",
      "  Downloading opencv_python-4.5.4.58-cp36-cp36m-manylinux2014_x86_64.whl (60.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 60.3 MB 82 kB/s s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /srv/conda/envs/notebook/lib/python3.6/site-packages (from opencv-python) (1.19.5)\n",
      "Installing collected packages: opencv-python\n",
      "Successfully installed opencv-python-4.5.4.58\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0d126930",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "\u001b[K     |████████████████████████████████| 97 kB 744 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.2.1-py3-none-any.whl (33 kB)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1273 sha256=4247e4aaf693876b4d9eb41751bcff8694caa55eec49d5ae11922e7fbf40f1c2\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/19/f5/6d/a97dd4f22376d4472d5f4c76c7646876052ff3166b3cf71050\n",
      "Successfully built bs4\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "Successfully installed beautifulsoup4-4.10.0 bs4-0.0.1 soupsieve-2.2.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "67ac5f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.0.1-py3-none-any.whl (148 kB)\n",
      "\u001b[K     |████████████████████████████████| 148 kB 16.2 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab2de410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tqdm\n",
      "  Downloading tqdm-4.62.3-py2.py3-none-any.whl (76 kB)\n",
      "\u001b[K     |████████████████████████████████| 76 kB 2.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tqdm\n",
      "Successfully installed tqdm-4.62.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0f282dd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libGL.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-5e4052ed8077>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpydicom\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: libGL.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.seterr(all='ignore')\n",
    "import os, os.path\n",
    "import pydicom\n",
    "import cv2\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.ndimage\n",
    "import scipy.signal\n",
    "from scipy.interpolate import RegularGridInterpolator as rgi\n",
    "import collections\n",
    "import copy\n",
    "import xlsxwriter\n",
    "from datetime import date\n",
    "from tqdm import tqdm\n",
    "import statistics\n",
    "import gc\n",
    "from skimage.transform import rotate\n",
    "import scipy.interpolate as inter\n",
    "from scipy.ndimage.interpolation import shift\n",
    "from numpy.polynomial import Polynomial as Poly\n",
    "from operator import itemgetter\n",
    "from itertools import *\n",
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5220cf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm_list_builder(path, test_text = \"\"):\n",
    "    # function to get list of dcm_files from dcm directory\n",
    "    dcm_path_list = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(path,topdown=True):\n",
    "        if dirpath not in dcm_path_list:\n",
    "            for filename in filenames:\n",
    "                try:\n",
    "                    tmp_str = str('\\\\\\\\?\\\\' + os.path.join(dirpath, filename))\n",
    "                    ds = pydicom.read_file(tmp_str, stop_before_pixels = True)\n",
    "                    if dirpath not in dcm_path_list:\n",
    "                        dcm_path_list.append(dirpath)\n",
    "                except:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "    return dcm_path_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "60bf39ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm_reader(dcm_path):\n",
    "    #read dcm_files from path\n",
    "    #path certainly contains DCM files, as tested by dcm_list_builder function\n",
    "    dcm_files = []\n",
    "    for (dirpath, dirnames, filenames) in os.walk(dcm_path,topdown=False):\n",
    "        for filename in filenames:\n",
    "            try:\n",
    "                if not filename == 'DIRFILE':   \n",
    "                    dcm_file = str('\\\\\\\\?\\\\' + os.path.join(dirpath, filename))\n",
    "                    pydicom.read_file(dcm_file, stop_before_pixels = True)\n",
    "                    dcm_files.append(dcm_file)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "    read_RefDs = True\n",
    "    while read_RefDs:\n",
    "        for index in range(len(dcm_files)):\n",
    "            try:\n",
    "                RefDs = pydicom.read_file(dcm_files[index], stop_before_pixels = False)\n",
    "                read_RefDs = False\n",
    "                break\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    slice_thick_ori = RefDs.SliceThickness\n",
    "    \n",
    "    ConstPixelDims = (int(RefDs.Rows), int(RefDs.Columns), len(dcm_files))\n",
    "    dcm_array = np.zeros([ConstPixelDims[0],ConstPixelDims[1],len(dcm_files)],\\\n",
    "                          dtype=RefDs.pixel_array.dtype) \n",
    "\n",
    "    instances = []    \n",
    "    for filenameDCM in dcm_files:\n",
    "        try:\n",
    "            ds = pydicom.read_file(filenameDCM, stop_before_pixels = True)\n",
    "            instances.append(int(ds.InstanceNumber))\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    instances.sort()\n",
    "\n",
    "    index = 0\n",
    "    for filenameDCM in dcm_files:\n",
    "        try:\n",
    "            ds = pydicom.read_file(filenameDCM)\n",
    "            dcm_array[:,:,instances.index(ds.InstanceNumber)] = ds.pixel_array\n",
    "            if ds.InstanceNumber in instances[:2]:\n",
    "                if ds.InstanceNumber == instances[0]:\n",
    "                    loc_1 = ds.SliceLocation\n",
    "                else:\n",
    "                    loc_2 = ds.SliceLocation\n",
    "            index += 1\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "    try:\n",
    "        RefDs.SliceThickness = abs(loc_1 - loc_2)\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "        \n",
    "    dcm_array = dcm_array * RefDs.RescaleSlope + RefDs.RescaleIntercept\n",
    "    return RefDs, dcm_array, slice_thick_ori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bbbc93a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_def(calcium_threshold_declaration):\n",
    "    if calcium_threshold_declaration == 'default':\n",
    "        if header.KVP == 120:\n",
    "            return 130\n",
    "        elif header.KVP == 100:\n",
    "            return 147\n",
    "    elif calcium_threshold_declaration == 'monoE':\n",
    "        if 'ME40KEV' in header.ImageType:\n",
    "            return 339\n",
    "        elif 'ME50KEV' in header.ImageType:\n",
    "            return 229\n",
    "        elif 'ME60KEV' in header.ImageType:\n",
    "            return 167\n",
    "        elif 'ME70KEV' in header.ImageType:\n",
    "            return 132\n",
    "        elif 'ME80KEV' in header.ImageType:\n",
    "            return 110\n",
    "        elif 'ME90KEV' in header.ImageType:\n",
    "            return 97\n",
    "        elif 'ME100KEV' in header.ImageType:\n",
    "            return 87\n",
    "        elif 'ME110KEV' in header.ImageType:\n",
    "            return 81\n",
    "        elif 'ME120KEV' in header.ImageType:\n",
    "            return 77\n",
    "        elif 'ME130KEV' in header.ImageType:\n",
    "            return 73\n",
    "        elif 'ME140KEV' in header.ImageType:\n",
    "            return 71\n",
    "        elif 'ME150KEV' in header.ImageType:\n",
    "            return 69\n",
    "        elif 'ME160KEV' in header.ImageType:\n",
    "            return 67\n",
    "        elif 'ME170KEV' in header.ImageType:\n",
    "            return 66\n",
    "        elif 'ME180KEV' in header.ImageType:\n",
    "            return 65\n",
    "        elif 'ME190KEV' in header.ImageType:\n",
    "            return 64\n",
    "        else:\n",
    "            return 130\n",
    "\n",
    "    else:\n",
    "        # if header.ConvolutionKernel == 'Sa36f'\\\n",
    "        #     or header.ConvolutionKernel == 'Qr36f'\\\n",
    "        #     or header.ConvolutionKernel[0] == 'Sa36f':\n",
    "        #         # kVp - base HU pair values are taken from high-dose scans\n",
    "        #         kVp_baseHU = {'70':-4, '80':12, '90':22, '100':29, '110':33,\\\n",
    "        #                       '120':35, '130':41, '140':44, '150':46, 'Sn100':48, 'Sn150': 70}\n",
    "        #         # calculation of treshold based on Siemens white-paper\n",
    "        #         if 'SN' in header.FilterType:\n",
    "        #             threshold = 95 + kVp_baseHU['Sn' + str(header.KVP)]\n",
    "        #         else:\n",
    "        #             threshold = 95 + kVp_baseHU[str(header.KVP)]\n",
    "        if header.ConvolutionKernel == 'Sa36f' or header.ConvolutionKernel[0] == 'Sa36f':\n",
    "            threshold = 130\n",
    "        elif header.KVP == 100:\n",
    "            threshold = 147\n",
    "        else:\n",
    "            threshold = 130\n",
    "    return threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1e1402f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scoring_method_selector():\n",
    "    if scoring_method == 'default':\n",
    "        if ('TOSHIBA' in header.Manufacturer or 'Toshiba' in header.Manufacturer):\n",
    "            return 'CANON'\n",
    "        elif ('CANON' in header.Manufacturer or 'Canon' in header.Manufacturer):\n",
    "            return 'CANON'\n",
    "        elif ('SIEMENS' in header.Manufacturer or 'Siemens' in header.Manufacturer):\n",
    "            return 'SIEMENS'\n",
    "        elif ('PHILIPS' in header.Manufacturer or 'Philips' in header.Manufacturer):\n",
    "            return 'Philips'\n",
    "        elif ('GE' in header.Manufacturer or 'Ge' in header.Manufacturer):\n",
    "            return 'GE'       \n",
    "        else:\n",
    "            print('Manufacturer unknown, consider specifying')\n",
    "            return header.Manufacturer.upper()\n",
    "        \n",
    "    elif (scoring_method == 'Siemens' or scoring_method == 'Siemens'):\n",
    "        return 'SIEMENS'\n",
    "    elif (scoring_method == 'Canon' or scoring_method == 'CANON'):\n",
    "        return 'CANON'\n",
    "    elif (scoring_method == 'Toshiba' or scoring_method == 'TOSHIBA'):\n",
    "        return 'CANON'\n",
    "    elif (scoring_method == 'Philips' or scoring_method == 'PHILIPS'):\n",
    "        return 'PHILIPS'\n",
    "    elif (scoring_method == 'Ge' or scoring_method == 'GE'):\n",
    "        return 'GE'\n",
    "    elif (scoring_method == 'literature'):\n",
    "        return 'Literature'\n",
    "    else:\n",
    "        print('Error, scoring method unknown, using default')\n",
    "        return header.Manufacturer.upper()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "510f64ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCircle(point_1, point_2, point_3) : \n",
    "    x1, y1 = point_1\n",
    "    x2, y2 = point_2\n",
    "    x3, y3 = point_3\n",
    "    \n",
    "    x12 = x1 - x2 \n",
    "    x13 = x1 - x3  \n",
    "    y12 = y1 - y2  \n",
    "    y13 = y1 - y3 \n",
    "    y31 = y3 - y1  \n",
    "    y21 = y2 - y1\n",
    "    x31 = x3 - x1  \n",
    "    x21 = x2 - x1 \n",
    " \n",
    "    sx13 = x1**2 - x3**2  \n",
    "    sy13 = y1**2 - y3**2\n",
    "    sx21 = x2**2 - x1**2  \n",
    "    sy21 = y2**2 - y1**2  \n",
    "  \n",
    "    f = (((sx13) * (x12) + (sy13) * (x12) + (sx21) * (x13) +\\\n",
    "          (sy21) * (x13)) // (2 * ((y31) * (x12) - (y21) * (x13)))) \n",
    "              \n",
    "    g = (((sx13) * (y12) + (sy13) * (y12) + (sx21) * (y13) + (sy21) *\\\n",
    "          (y13)) // (2 * ((x31) * (y12) - (x21) * (y13))))  \n",
    "  \n",
    "    # eqn of circle be x^2 + y^2 + 2*g*x + 2*f*y + c = 0 where centre is (h = -g, k = -f)  \n",
    "    center_insert = [-g,-f]\n",
    "\n",
    "    return center_insert\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3282b1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm_masked(array_used = None, radius_val = 95, slice_used_center = None):\n",
    "    try:\n",
    "        pixel_size = header.PixelSpacing[0]\n",
    "    except:\n",
    "        FOV = header.ReconstructionDiameter\n",
    "        matrix_size = header.Rows\n",
    "    \n",
    "        pixel_size = FOV / matrix_size\n",
    "    \n",
    "    radius = (radius_val/2) / pixel_size\n",
    "    \n",
    "    central_image = array_used[:,:,slice_used_center].copy()\n",
    "    \n",
    "    central_image[central_image > -200] = 0\n",
    "    central_image[central_image != 0] = 1\n",
    "\n",
    "    image_kernel = math.ceil(5 / header.PixelSpacing[0])\n",
    "    if image_kernel % 2 == 0:\n",
    "        image_kernel += 1\n",
    "    central_image = scipy.signal.medfilt2d(central_image, image_kernel)\n",
    "    \n",
    "    # plt.imshow(central_image)\n",
    "    # plt.show()\n",
    "\n",
    "    center = [int(array_used.shape[0] / 2), int(array_used.shape[1] / 2)]\n",
    "    \n",
    "    a = central_image.copy()\n",
    "    for index in range(int(array_used.shape[1] / 2)):\n",
    "        if (central_image[center[0] + index, center[1] + index] == 1 and\\\n",
    "            central_image[center[0] + index, center[1] + index + 5] == 1):\n",
    "            point_1 = [center[0] + index, center[1] + index]\n",
    "            break\n",
    "        else:\n",
    "            a[center[0] + index, center[1] + index] = 2\n",
    "            pass\n",
    "    \n",
    "    for index in range(int(array_used.shape[1] / 2)):\n",
    "        if (central_image[center[0] + index, center[1] - index] == 1 and\\\n",
    "            central_image[center[0] + index, center[1] - index - 5] == 1):\n",
    "            point_2 = [center[0] + index, center[1] - index]\n",
    "            break\n",
    "        else:\n",
    "            a[center[0] + index, center[1] - index] = 2\n",
    "            pass\n",
    "        \n",
    "    # x_iter = range(center[0], int(array_used.shape[0]), 1)\n",
    "    # y_iter = range(center[1], int(array_used.shape[1]), 2)\n",
    "    # for tmp_x, tmp_y in zip(x_iter, y_iter):\n",
    "    #     if (central_image[tmp_x, tmp_y] == 1 and central_image[tmp_x + 5, tmp_y + 5] == 1):\n",
    "    #         point_3 = [tmp_x, tmp_y]\n",
    "    #         break\n",
    "    #     else:\n",
    "    #         a[tmp_x, tmp_y] = 2\n",
    "    #         pass\n",
    "        \n",
    "        \n",
    "    for index in range(int(array_used.shape[1] / 2)):\n",
    "        if (central_image[center[0] - index, center[1] - index] == 1 and\\\n",
    "            central_image[center[0] - index, center[1] - index - 5] == 1):\n",
    "            point_3 = [center[0] - index, center[1] - index]\n",
    "            break\n",
    "        else:\n",
    "            a[center[0] - index, center[1] - index] = 2\n",
    "            pass\n",
    "        \n",
    "    # plt.imshow(a)\n",
    "    # plt.show()\n",
    "    \n",
    "    center_insert = findCircle(point_1, point_2, point_3)\n",
    "\n",
    "    Y, X = np.ogrid[:header.Rows, :header.Columns]\n",
    "    dist_from_center = np.sqrt((X - center_insert[1])**2 + (Y-center_insert[0])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius  \n",
    "    masked_array = np.zeros_like(array_used)\n",
    "    for index in range(array_used.shape[2]):\n",
    "        masked_array[:,:,index] = array_used[:,:,index] * mask\n",
    "\n",
    "    return masked_array, center_insert, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "970491c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm_masked_QRMAbdomen(radius_val = 95):\n",
    " \n",
    "    try:\n",
    "        pixel_size = header.PixelSpacing[0]\n",
    "    except:\n",
    "        FOV = header.ReconstructionDiameter\n",
    "        matrix_size = header.Rows\n",
    "    \n",
    "        pixel_size = FOV / matrix_size\n",
    "    \n",
    "    radius = (radius_val/2) / pixel_size\n",
    "    \n",
    "    if phantom == 'CCI':\n",
    "        if 'QRM-ABDOMEN.XA._.0003' in dcm_name:\n",
    "            center_insert = [215, 271]\n",
    "        elif 'QRM-ABDOMEN.XA._.0004' in dcm_name:\n",
    "            center_insert = [210, 269]\n",
    "        elif 'QRM-ABDOMEN.XA._.0008' in dcm_name:\n",
    "            center_insert = [218, 266]\n",
    "        elif 'QRM-ABDOMEN.XA._.0009' in dcm_name:\n",
    "            center_insert = [210, 270]\n",
    "        elif 'QRM-ABDOMEN.XA._.0010' in dcm_name:\n",
    "            center_insert = [212, 273]\n",
    "        elif 'QRM-ABDOMEN.XA._.0011' in dcm_name:\n",
    "            center_insert = [217, 272]\n",
    "        elif 'QRM-ABDOMEN.XA._.0012' in dcm_name:\n",
    "            center_insert = [217, 272]\n",
    "        elif 'QRM-ABDOMEN.XA._.0013' in dcm_name:\n",
    "            center_insert = [217, 276]\n",
    "        elif 'QRM-ABDOMEN.XA._.0014' in dcm_name:\n",
    "            center_insert = [216, 280]\n",
    "        elif 'QRM-ABDOMEN.XA._.0015' in dcm_name:\n",
    "            center_insert = [215, 283]\n",
    "        elif 'QRM-ABDOMEN.XA._.0016' in dcm_name:\n",
    "            center_insert = [217, 283]\n",
    "        elif 'QRM-ABDOMEN.XA._.0017' in dcm_name:\n",
    "            center_insert = [215, 281]\n",
    "        elif 'QRM-ABDOMEN.XA._.0018' in dcm_name:\n",
    "            center_insert = [216, 273]\n",
    "        elif 'QRM-ABDOMEN.XA._.0019' in dcm_name:\n",
    "            center_insert = [215, 281]\n",
    "        elif 'QRM-ABDOMEN.XA._.0020' in dcm_name:\n",
    "            center_insert = [215, 280]\n",
    "        elif 'QRM-ABDOMEN.XA._.0051' in dcm_name:\n",
    "            center_insert = [220, 294]\n",
    "        elif 'QRM-ABDOMEN.XA._.0052' in dcm_name:\n",
    "            center_insert = [221, 295]\n",
    "        elif 'QRM-ABDOMEN.XA._.0053' in dcm_name:\n",
    "            center_insert = [221, 295]\n",
    "        elif 'QRM-ABDOMEN.XA._.0054' in dcm_name:\n",
    "            center_insert = [221, 293]\n",
    "        elif 'QRM-ABDOMEN.XA._.0055' in dcm_name:\n",
    "            center_insert = [222, 297]\n",
    "        elif 'QRM-ABDOMEN.XA._.0056' in dcm_name:\n",
    "            center_insert = [220, 298]\n",
    "        elif 'QRM-ABDOMEN.XA._.0057' in dcm_name:\n",
    "            center_insert = [221, 296]\n",
    "        elif 'QRM-ABDOMEN.XA._.0058' in dcm_name:\n",
    "            center_insert = [221, 296]\n",
    "        elif 'QRM-ABDOMEN.XA._.0059' in dcm_name:\n",
    "            center_insert = [223, 295]\n",
    "        elif 'QRM-ABDOMEN.XA._.0060' in dcm_name:\n",
    "            center_insert = [223, 297]\n",
    "        elif 'QRM-ABDOMEN.XA._.0061' in dcm_name:\n",
    "            center_insert = [223, 296]\n",
    "        elif 'QRM-ABDOMEN.XA._.0062' in dcm_name:\n",
    "            center_insert = [224, 297]\n",
    "        elif 'QRM-ABDOMEN.XA._.0063' in dcm_name:\n",
    "            center_insert = [222, 302]\n",
    "        elif 'QRM-ABDOMEN.XA._.0064' in dcm_name:\n",
    "            center_insert = [224, 302]\n",
    "        elif 'QRM-ABDOMEN.XA._.0065' in dcm_name:\n",
    "            center_insert = [222, 305]\n",
    "        elif 'Abd_large_rep' in dcm_name:\n",
    "            center_insert = [224, 254]\n",
    "        elif 'Abdomen_small' in dcm_name:\n",
    "            center_insert = [216, 251]\n",
    "\n",
    "    else:\n",
    "        if 'Abd_large_rep' in dcm_name:\n",
    "            center_insert = [219, 256]\n",
    "        elif 'Abdomen_small' in dcm_name:\n",
    "            center_insert = [238, 254]\n",
    "    \n",
    "    \n",
    "    Y, X = np.ogrid[:header.Rows, :header.Columns]\n",
    "    dist_from_center = np.sqrt((X - center_insert[1])**2 + (Y-center_insert[0])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius  \n",
    "    masked_array = np.zeros_like(dcm_array)\n",
    "    for index in range(dcm_array.shape[2]):\n",
    "        masked_array[:,:,index] = dcm_array[:,:,index] * mask\n",
    "   \n",
    "    return masked_array, center_insert, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "39f913f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcm_interpolation(array):\n",
    "    # define interpolation method via order:\n",
    "    array_int = array.copy()\n",
    "    int_header = copy.deepcopy(header)\n",
    "    \n",
    "    int_header.SliceThickness = header.PixelSpacing[0]\n",
    "    \n",
    "    # actual interpolation\n",
    "    steps = [header.Rows + 1, header.Columns + 1, header.SliceThickness]    # original step sizes\n",
    "    x, y, z = [steps[k] * np.arange(array_int.shape[k]) for k in range(3)]  # original grid\n",
    "    f = rgi((x, y, z), array_int)    # interpolator\n",
    "    \n",
    "    dx, dy, dz = header.Rows, header.Columns,  header.PixelSpacing[0]    # new step sizes\n",
    "    new_grid = np.mgrid[0:x[-1]:dx, 0:y[-1]:dy, 0:z[-1]:dz]   # new grid\n",
    "    new_grid = np.moveaxis(new_grid, (0, 1, 2, 3), (3, 0, 1, 2))  # reorder axes for evaluation\n",
    "    new_values = f(new_grid)\n",
    "\n",
    "    return int_header, new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6b1ab52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AS_weight_calc(mask, calcium_image_slice):\n",
    "    maximum_voxel = (mask * calcium_image_slice).max()\n",
    "    \n",
    "    try:\n",
    "        if calcium_threshold_declaration == 'monoE':\n",
    "            if 'ME40KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 1029:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 773:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 515:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME50KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 694:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 522:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 348:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME60KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 508:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 381:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 254:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME70KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 400:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 300:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 200:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME80KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 335:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 251:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 168:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME90KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 293:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 220:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 147:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME100KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 265:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 199:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 133:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME110KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 246:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 185:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 123:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME120KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 232:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 174:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 116:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME130KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 222:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 167:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 111:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME140KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 215:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 161:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 107:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME150KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 209:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 157:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 104:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME160KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 204:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 153:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 102:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME170KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 201:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 151:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 100:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME180KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 198:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 148:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 99:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "            elif 'ME190KEV' in header.ImageType:\n",
    "                if maximum_voxel >= 195:\n",
    "                    AS_weight = 4\n",
    "                elif maximum_voxel >= 147:\n",
    "                    AS_weight = 3\n",
    "                elif maximum_voxel >= 98:\n",
    "                    AS_weight = 2\n",
    "                else:\n",
    "                    AS_weight = 1\n",
    "        else:\n",
    "            if maximum_voxel >= 400:\n",
    "                AS_weight = 4\n",
    "            elif maximum_voxel >= 300:\n",
    "                AS_weight = 3\n",
    "            elif maximum_voxel >= 200:\n",
    "                AS_weight = 2\n",
    "            else:\n",
    "                AS_weight = 1\n",
    "            \n",
    "    except:\n",
    "        if maximum_voxel >= 400:\n",
    "            AS_weight = 4\n",
    "        elif maximum_voxel >= 300:\n",
    "            AS_weight = 3\n",
    "        elif maximum_voxel >= 200:\n",
    "            AS_weight = 2\n",
    "        else:\n",
    "            AS_weight = 1\n",
    "        \n",
    "    \n",
    "\n",
    "    return AS_weight \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "41696b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def angle_calc(side1, side2):\n",
    "    #Calculate angle between two sides of rectangular triangle\n",
    "    if side1 == 0:\n",
    "        angle = 0\n",
    "    elif side2 == 0:\n",
    "        angle = math.pi / 2\n",
    "    else:\n",
    "        angle = math.atan(side1 / side2)\n",
    "    \n",
    "    return angle\n",
    "\n",
    "\n",
    "def create_circular_mask(h, w, center_circle, radius_circle):\n",
    "\n",
    "    Y, X = np.ogrid[:h, :w]\n",
    "    dist_from_center = np.sqrt((X - center_circle[0])**2 + (Y-center_circle[1])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius_circle\n",
    "    \n",
    "    return mask\n",
    "\n",
    "\n",
    "def mass_mean_def(array):\n",
    "    # Calculation of mean value within masked image\n",
    "    if array.max() == 0:\n",
    "        mass_mean = 0\n",
    "    else:\n",
    "        array[array < calcium_threshold] = 0\n",
    "        mass_mean = array.sum() / np.count_nonzero(array)\n",
    "\n",
    "    return mass_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "65da43ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCI_calcium_image():\n",
    "    # threshold array according to calcium_threshold \n",
    "    # simultaneously make image binary\n",
    "    array = dcm_array.copy()\n",
    "    array[array < 1.1*calcium_threshold] = 0\n",
    "    array[array > 0] = 1\n",
    "    array = array.astype(dtype = np.uint8)\n",
    "    \n",
    "    CCI_5mm_num_pixels = int(math.pi * (5/2)**2 / header.PixelSpacing[0]**2)\n",
    "    cal_rod_num_pixels = int(math.pi * (20/2)**2 / header.PixelSpacing[0]**2)\n",
    "\n",
    "    image_kernel = math.ceil(5 / header.PixelSpacing[0])\n",
    "    if image_kernel % 2 == 0:\n",
    "        image_kernel += 1\n",
    "        \n",
    "    # plt.imshow(array[:,:,20], cmap='bone')\n",
    "    # plt.xticks(fontsize = 35)\n",
    "    # plt.yticks(fontsize = 35)\n",
    "    # plt.show()\n",
    "    \n",
    "    slice_dict =  {}\n",
    "    large_index = []\n",
    "    cal_rod_dict = {}\n",
    "    for idx in range(array.shape[2]):\n",
    "        array_filtered = scipy.signal.medfilt2d(array[:,:,idx], image_kernel)\n",
    "        output = cv2.connectedComponentsWithStats(array_filtered, comp_connect,cv2.CV_32S)\n",
    "        count_5mm = 0\n",
    "        for index in range(1,output[0]):\n",
    "            if output[2][index][4] in range(int(CCI_5mm_num_pixels * 0.6),\\\n",
    "                     int(CCI_5mm_num_pixels * 1.5)):\n",
    "                count_5mm += 1\n",
    "            elif output[2][index][4] in range(int(cal_rod_num_pixels * 0.7),\\\n",
    "                     int(cal_rod_num_pixels * 1.3)):\n",
    "                cal_rod_dict[index] = [int(output[3][index][1]), int(output[3][index][0])]\n",
    "        if (count_5mm > 0 and count_5mm < 4):\n",
    "            slice_dict[idx] = count_5mm\n",
    "    \n",
    "        poppable_keys = []\n",
    "        for key in cal_rod_dict.keys():\n",
    "            start_coordinate = [cal_rod_dict[key][0], cal_rod_dict[key][1]]\n",
    "            \n",
    "            x_right = 0\n",
    "            while array_filtered[start_coordinate[0], start_coordinate[1] + x_right] == 1:\n",
    "                x_right += 1\n",
    "            \n",
    "            x_left = 0\n",
    "            while array_filtered[start_coordinate[0], start_coordinate[1] - x_left] == 1:\n",
    "                x_left += 1\n",
    "            \n",
    "            y_top = 0\n",
    "            while array_filtered[start_coordinate[0] + y_top, start_coordinate[1]] == 1:\n",
    "                y_top += 1\n",
    "            \n",
    "            y_bottom = 0\n",
    "            while array_filtered[start_coordinate[0] - y_bottom, start_coordinate[1]] == 1:\n",
    "                y_bottom += 1\n",
    "                \n",
    "            x_dist = x_right + x_left\n",
    "            y_dist = y_top + y_bottom\n",
    "            \n",
    "            if x_dist not in range(int(0.7*y_dist), int(1.2*y_dist)):\n",
    "                poppable_keys.append(key)\n",
    "            else:\n",
    "                pass\n",
    "            \n",
    "        for key in poppable_keys:\n",
    "                cal_rod_dict.pop(key)\n",
    "                \n",
    "        if len(cal_rod_dict) == 0:\n",
    "            pass\n",
    "        else:\n",
    "            large_index.append(idx)\n",
    "    # flipped_index = np.where(dcm_array[center[0], center[1], :] == max(dcm_array[center[0], center[1], :]))[0][0]\n",
    "    flipped_index = int(statistics.median(large_index))\n",
    "\n",
    "    edge_index = []\n",
    "    if flipped_index < (dcm_array.shape[2] / 2):\n",
    "        flipped = -1\n",
    "        for element in large_index:\n",
    "            if element > (dcm_array.shape[2] / 2):\n",
    "                edge_index.append(element)\n",
    "        if not edge_index:\n",
    "            pass\n",
    "        else:\n",
    "            for index_edge in range(min(edge_index), dcm_array.shape[2]):\n",
    "                try:\n",
    "                    del(slice_dict[index_edge])\n",
    "                except:\n",
    "                    pass\n",
    "            for element2 in edge_index:\n",
    "                large_index.remove(element2)\n",
    "                \n",
    "        for element in range(max(large_index)):\n",
    "            try:\n",
    "                del(slice_dict[element])\n",
    "            except:\n",
    "                pass        \n",
    "    else:\n",
    "        flipped = 1\n",
    "        for element in large_index:\n",
    "            if element < (dcm_array.shape[2] / 2):\n",
    "                edge_index.append(element)\n",
    "        if not edge_index:\n",
    "            pass\n",
    "        else:\n",
    "            for index_edge in range(max(edge_index)):\n",
    "                try:\n",
    "                    del(slice_dict[index_edge])\n",
    "                except:\n",
    "                    pass\n",
    "            for element2 in edge_index:\n",
    "                large_index.remove(element2)\n",
    "        for element in range(min(large_index), dcm_array.shape[2]):\n",
    "            try:\n",
    "                del(slice_dict[element])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    poppable_keys = []        \n",
    "    if flipped == -1:\n",
    "        for key in slice_dict.keys():\n",
    "            if key > (flipped_index + (55 / header.SliceThickness)):\n",
    "                poppable_keys.append(key)\n",
    "    elif flipped == 1:\n",
    "        for key in slice_dict.keys():\n",
    "            if key < (flipped_index - (55 / header.SliceThickness)):\n",
    "                poppable_keys.append(key)\n",
    "    for key in poppable_keys:\n",
    "                slice_dict.pop(key)            \n",
    "                \n",
    "       \n",
    "    max_key, _ = max(zip(slice_dict.values(), slice_dict.keys()))\n",
    "\n",
    "    max_keys = []\n",
    "    for key in slice_dict.keys():\n",
    "        if slice_dict[key] is max_key:\n",
    "            max_keys.append(key)\n",
    "    \n",
    "    slice_CCI = int(statistics.median(max_keys))\n",
    "    \n",
    "    array = dcm_array.copy()\n",
    "    array[array < calcium_threshold] = 0\n",
    "    array[array > 0] = 1\n",
    "    array = array.astype(dtype = np.uint8)\n",
    "    \n",
    "    calcium_image = array * dcm_array\n",
    "    quality_slice = round(slice_CCI - flipped * (20 / header.SliceThickness))\n",
    "\n",
    "    cal_rod_slice = slice_CCI + (flipped * int(30 / header.SliceThickness))\n",
    "    \n",
    "    return calcium_image, slice_CCI, quality_slice, cal_rod_slice, flipped\n",
    "\n",
    "def interp_2D(array, factor, interp_type = 'cubic'):\n",
    "    new_size = complex(array.shape[0] * factor)\n",
    "    vals = np.reshape(array,(array.shape[0]*array.shape[1]))\n",
    "    \n",
    "    pts = np.array([[i,j] for i in range(array.shape[0]) for j in range(array.shape[1])] )\n",
    "    \n",
    "    grid_x, grid_y = np.mgrid[0:array.shape[0]-1:new_size, 0:array.shape[1]-1:new_size]\n",
    "\n",
    "    new_array = inter.griddata(pts, vals, (grid_x, grid_y), method=interp_type)\n",
    "    return new_array\n",
    "\n",
    "\n",
    "def nps_calc(image, num_ROIs = 15, rad = 32, ROI_size = 15, plot_NPS = False):\n",
    "    # init\n",
    "    ROI_image = image.copy()\n",
    "    \n",
    "    radius = int(rad / header.PixelSpacing[0])\n",
    "    size_ROI = int(ROI_size / header.PixelSpacing[0])\n",
    "    if (size_ROI % 2) == 0:  \n",
    "        size_ROI += 1\n",
    "\n",
    "    Spacing_X = header.PixelSpacing[0]\n",
    "    Spacing_Y = header.PixelSpacing[1]\n",
    "    num_x = size_ROI\n",
    "    num_y = size_ROI\n",
    "    \n",
    "    FFT_image_total = np.zeros([size_ROI, size_ROI])\n",
    "    \n",
    "    angle = 0\n",
    "    for index in range(num_ROIs - 1): #min 1 because center is added later\n",
    "        new_center = [center[0] + math.sin(angle) * radius, center[1] + math.cos(angle) * radius]\n",
    "        \n",
    "        dist_x_1 = int(new_center[0] - size_ROI/2)\n",
    "        dist_x_2 = int(new_center[0] + size_ROI/2)\n",
    "        dist_y_1 = int(new_center[1] - size_ROI/2)\n",
    "        dist_y_2 = int(new_center[1] - size_ROI/2)\n",
    "        \n",
    "        if (dist_x_2 - dist_x_1) != size_ROI:\n",
    "            dist_x_2 += size_ROI - (dist_x_2 - dist_x_1)\n",
    "        if (dist_y_2 - dist_y_1) != size_ROI:\n",
    "            dist_y_2 += size_ROI - (dist_y_2 - dist_y_1)\n",
    "        \n",
    "        image2 = image[dist_x_1: dist_x_2,dist_y_1: dist_y_2]\n",
    "    \n",
    "        angle += math.pi * 2 / (num_ROIs - 1)\n",
    "\n",
    "        ROI_image[int(new_center[0] - size_ROI/2): int(new_center[0] + size_ROI/2),\\\n",
    "                   int(new_center[1] - size_ROI/2): int(new_center[1] + size_ROI/2)] = 200\n",
    "                   \n",
    "        # 1. calculate mean of ROI and subtract from image\n",
    "        NPS_ROI = image2 - image2.mean()\n",
    "        \n",
    "        # 2. 2D fourier trasnform\n",
    "        FFT_image = np.fft.fftshift(np.fft.fft2(NPS_ROI))\n",
    "        FFT_image = abs(FFT_image)**2\n",
    "        FFT_image_total += FFT_image\n",
    "        \n",
    "    #add center ROI\n",
    "    image2 = image[int(center[0] - size_ROI/2): int(center[0] + size_ROI/2),\\\n",
    "                       int(center[1] - size_ROI/2): int(center[1] + size_ROI/2)]\n",
    "    ROI_image[int(center[0] - size_ROI/2): int(center[0] + size_ROI/2),\\\n",
    "                       int(center[1] - size_ROI/2): int(center[1] + size_ROI/2)] = 200\n",
    "    \n",
    "    NPS_ROI = image2 - image2.mean()\n",
    "    \n",
    "    FFT_image = np.fft.fftshift(np.fft.fft2(NPS_ROI))\n",
    "    FFT_image = abs(FFT_image)**2\n",
    "    FFT_image_total += FFT_image\n",
    "    \n",
    "    # calculate 2D NPS\n",
    "    res_FFT = FFT_image_total * ((Spacing_X * Spacing_Y) / (num_x * num_y)) / num_ROIs\n",
    "    factor = 3 #must be odd\n",
    "    size_ROI = factor * size_ROI\n",
    "    res_FFT = interp_2D(res_FFT, factor)\n",
    "    \n",
    "    rad_angles = 360\n",
    "    NPS_1D = res_FFT[int(size_ROI/2),int(size_ROI/2):] / rad_angles\n",
    "    for index in range(1,rad_angles):\n",
    "        tmp_FFT = res_FFT.copy()\n",
    "        tmp_FFT = rotate(tmp_FFT,index)\n",
    "        new_plot = tmp_FFT[int(size_ROI/2),int(size_ROI/2):] / rad_angles\n",
    "        NPS_1D += new_plot\n",
    "        \n",
    "    #NPS_x = np.linspace(0,1,int(size_ROI/2) + 1)\n",
    "    NPS_x = np.linspace(0,size_ROI*3, size_ROI*3) / (size_ROI*3 * (header.PixelSpacing[0]/3))\n",
    "    NPS_x = NPS_x[:math.ceil(size_ROI / 2)]\n",
    "    NPS = [NPS_x, NPS_1D.round(3)]\n",
    "    \n",
    "    if plot_NPS:\n",
    "        plt.imshow(ROI_image, cmap = 'bone')\n",
    "        plt.show()\n",
    "        plt.imshow(res_FFT, cmap = 'bone')\n",
    "        plt.show()\n",
    "        plt.scatter(NPS[0], NPS[1])\n",
    "        plt.plot(NPS[0], NPS[1])\n",
    "        plt.ylim(0,1.1*NPS[1].max())\n",
    "        plt.show()\n",
    "        \n",
    "    return NPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "74384552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mtf_calc(array, center_calc, plot_MTF = False):\n",
    "    dim = int(9 / header.PixelSpacing[0])\n",
    "    calc_array = array[center_calc[0]-dim:center_calc[0]+dim, center_calc[1]-dim:center_calc[1]+dim]\n",
    "   \n",
    "    calc_array_center = [int(calc_array.shape[0] / 2),int(calc_array.shape[0] / 2)]\n",
    "    \n",
    "    rad_angles = 360\n",
    "    ESF = calc_array[calc_array_center[0],calc_array_center[1] -\\\n",
    "                     int(5 / header.PixelSpacing[0]):calc_array_center[1]] / rad_angles\n",
    "    for index in range(1,rad_angles):\n",
    "        tmp_array = calc_array.copy()\n",
    "        tmp_array = rotate(tmp_array,index)\n",
    "        new_ESF = tmp_array[calc_array_center[0],calc_array_center[1] -\\\n",
    "                     int(5 / header.PixelSpacing[0]):calc_array_center[1]] / rad_angles\n",
    "        ESF += new_ESF\n",
    "    \n",
    "    LSF = np.abs(np.diff(ESF))\n",
    "    MTF = np.abs(np.fft.fft(LSF)) / sum(LSF)\n",
    "    MTF_x = np.linspace(0, len(MTF), len(MTF))\n",
    "    MTF_y = MTF[:int(len(LSF)/2)]\n",
    "    MTF_x = MTF_x[:int(len(LSF)/2)]\n",
    "    MTF = [MTF_x, MTF_y]\n",
    "\n",
    "    if plot_MTF:\n",
    "        plt.plot(MTF[0], MTF[1])\n",
    "        plt.show()\n",
    "    \n",
    "    MTF_0_5 = np.interp(0.5, np.flip(MTF_y,0), np.flip(MTF_x,0))\n",
    "\n",
    "    return MTF, MTF_0_5\n",
    "\n",
    "\n",
    "def min_area_det(manufacturer):\n",
    "    if 'SIEMENS' == manufacturer:\n",
    "        min_area = 0\n",
    "    elif 'PHILIPS' == manufacturer:\n",
    "        min_area = 0.5\n",
    "    elif 'CANON' == manufacturer:\n",
    "        min_area = 3 * header.PixelSpacing[0]**2 #min 3 connected voxels\n",
    "    elif 'GE' == manufacturer:\n",
    "        min_area = 1\n",
    "    elif 'Literature' == manufacturer:\n",
    "        min_area = 1\n",
    "    else:\n",
    "        min_area = 1\n",
    "        \n",
    "    return min_area\n",
    "\n",
    "def calcium_quality(D100_slices=None, D100_mask_BAS = np.zeros([1]), ROI_size = 55):\n",
    "    # Function to calculate three metrics:\n",
    "    # 1. Mean of ROI\n",
    "    # 2. SD of ROI\n",
    "    # 3. Agatston score of ROI (to see if noise is high enough to provide an Agatston score)\n",
    "    # 4. NPS\n",
    "    # 5. SNR\n",
    "    # 6. CNR\n",
    "    # 7. NTD\n",
    "    # 8. NPS peak frequency\n",
    "    if len(D100_mask_BAS) == 1:\n",
    "        pass\n",
    "    else:\n",
    "        D100_mask_BAS[D100_mask_BAS == 1] = -1\n",
    "        D100_mask_BAS[D100_mask_BAS > -1] = 1\n",
    "        D100_mask_BAS[D100_mask_BAS == -1] = 0\n",
    "\n",
    "    if phantom == 'CCI':\n",
    "        array = dcm_array[:,:,quality_slice].copy()\n",
    "    elif phantom == 'D100':\n",
    "        array = dcm_array[:,:,int((D100_slices[0] + D100_slices[1]) / 2)+1].copy()   \n",
    "    elif phantom == 'arteries':\n",
    "        array = dcm_array[:,:,int((calc1[1] + calc2[0]) / 2)].copy()\n",
    "        array = array * (1 - mask_scoring)\n",
    "        ROI_size = 50                                               \n",
    "                                                    \n",
    "    quality_size = int((ROI_size / header.PixelSpacing[0]) / 2)\n",
    "    \n",
    "    dcm_quality = array[int(center[0] - quality_size):int(center[0] + quality_size),\\\n",
    "                            int(center[1] - quality_size):int(center[1] + quality_size)]\n",
    "        \n",
    "    \n",
    "    qc = {}\n",
    "    qc['mean'] = round(dcm_quality.mean(),5)\n",
    "    qc['SD'] = round(dcm_quality.std(),5)\n",
    "    \n",
    "    if phantom == 'arteries':\n",
    "        qc['mean'] = dcm_quality.sum() / np.count_nonzero(dcm_quality)\n",
    "        tmp_SD = dcm_quality.copy()\n",
    "        tmp_SD[tmp_SD != 0] -= qc['mean']\n",
    "        qc['SD'] = math.sqrt((tmp_SD**2).sum() /\\\n",
    "                             np.count_nonzero(dcm_quality))\n",
    "     \n",
    "        array_binary = dcm_quality.copy()\n",
    "        array_binary[array_binary < calcium_threshold] = 0\n",
    "        array_binary[array_binary > 0] = 1\n",
    "        array_binary = array_binary.astype(dtype = np.uint8)\n",
    "        \n",
    "        output = cv2.connectedComponentsWithStats(array_binary, comp_connect, cv2.CV_32S)\n",
    "        qc_areas = []\n",
    "        for index in range(output[0]):\n",
    "            qc_areas.append(output[2][index][4])\n",
    "            \n",
    "        qc_max_area = qc_areas.index(max(qc_areas))\n",
    "        \n",
    "        AS_slice = 0        \n",
    "        for component_index in range(1,output[0]):\n",
    "            if component_index != qc_max_area:\n",
    "                tmp_array = output[1].copy()\n",
    "                tmp_array[tmp_array != component_index] = 0\n",
    "                tmp_array = tmp_array * dcm_quality\n",
    "    \n",
    "                area = output[2][component_index][4] * header.PixelSpacing[0]**2\n",
    "                \n",
    "                min_area = min_area_det(header.Manufacturer)\n",
    "        \n",
    "                if area > min_area:\n",
    "                    AS_weight = AS_weight_calc(np.ones_like(tmp_array), tmp_array)\n",
    "                    AS = area * AS_weight\n",
    "                    AS_slice += AS                 \n",
    "            \n",
    "        qc['AS'] = round(AS_slice,5)\n",
    "        \n",
    "    elif phantom == 'CCI':\n",
    "        AS_D100 = 0\n",
    "        BAS_D100 = {}\n",
    "        \n",
    "        array_BAS_CCI = dcm_array[:,:,CCI_slice].copy()\n",
    "        # plt.imshow(array_BAS_CCI)\n",
    "        # plt.show()\n",
    "        array_BAS_CCI = array_BAS_CCI * CCI_mask_BAS\n",
    "        # plt.imshow(array_BAS_CCI)\n",
    "        # plt.show()\n",
    "        \n",
    "        array_binary_BAS = array_BAS_CCI.copy()\n",
    "        array_binary_BAS[array_binary_BAS < calcium_threshold] = 0\n",
    "        array_binary_BAS[array_binary_BAS > 0] = 1\n",
    "        array_binary_BAS = array_binary_BAS.astype(dtype = np.uint8)\n",
    "        \n",
    "        output_BAS = cv2.connectedComponentsWithStats(array_binary_BAS, comp_connect, cv2.CV_32S)\n",
    "        qc_areas_BAS = []\n",
    "        for index2 in range(output_BAS[0]):\n",
    "            qc_areas_BAS.append(output_BAS[2][index2][4])\n",
    "            \n",
    "        qc_max_area_BAS = qc_areas_BAS.index(max(qc_areas_BAS))\n",
    "        \n",
    "        AS_slice = 0        \n",
    "        for component_index in range(1,output_BAS[0]):\n",
    "            if component_index != qc_max_area_BAS:\n",
    "                tmp_array = output_BAS[1].copy()\n",
    "                tmp_array[tmp_array != component_index] = 0\n",
    "                tmp_array = tmp_array * array_BAS_CCI\n",
    "    \n",
    "                area = output_BAS[2][component_index][4] * header.PixelSpacing[0]**2\n",
    "                \n",
    "                min_area = min_area_det(header.Manufacturer)\n",
    "        \n",
    "                if area > min_area:\n",
    "                    AS_weight = AS_weight_calc(np.ones_like(tmp_array), tmp_array)\n",
    "                    AS = area * AS_weight\n",
    "                    AS_slice += AS       \n",
    "                \n",
    "                \n",
    "        qc['AS'] = round(AS_slice,5)\n",
    "        # To be done: exclude masked CAC from mean / SD calculation\n",
    "        # qc['mean'] = round(array_BAS_CCI.mean(),5)\n",
    "        # qc['SD'] = round(array_BAS_CCI.std(),5)\n",
    "               \n",
    "        \n",
    "    else:\n",
    "        AS_D100 = 0\n",
    "        BAS_D100 = {}\n",
    "        for index in D100_slices:\n",
    "            array_BAS_D100 = dcm_array[:,:,index].copy()\n",
    "            # plt.imshow(array_BAS_D100)\n",
    "            # plt.show()\n",
    "            array_BAS_D100 = array_BAS_D100 * D100_mask_BAS\n",
    "            # plt.imshow(array_BAS_D100)\n",
    "            # plt.show()\n",
    "            \n",
    "            array_binary_BAS = array_BAS_D100.copy()\n",
    "            array_binary_BAS[array_binary_BAS < calcium_threshold] = 0\n",
    "            array_binary_BAS[array_binary_BAS > 0] = 1\n",
    "            array_binary_BAS = array_binary_BAS.astype(dtype = np.uint8)\n",
    "            \n",
    "            output_BAS = cv2.connectedComponentsWithStats(array_binary_BAS, comp_connect, cv2.CV_32S)\n",
    "            qc_areas_BAS = []\n",
    "            for index2 in range(output_BAS[0]):\n",
    "                qc_areas_BAS.append(output_BAS[2][index2][4])\n",
    "                \n",
    "            qc_max_area_BAS = qc_areas_BAS.index(max(qc_areas_BAS))\n",
    "            \n",
    "            AS_slice = 0        \n",
    "            for component_index in range(1,output_BAS[0]):\n",
    "                if component_index != qc_max_area_BAS:\n",
    "                    tmp_array = output_BAS[1].copy()\n",
    "                    tmp_array[tmp_array != component_index] = 0\n",
    "                    tmp_array = tmp_array * array_BAS_D100\n",
    "        \n",
    "                    area = output_BAS[2][component_index][4] * header.PixelSpacing[0]**2\n",
    "                    \n",
    "                    min_area = min_area_det(header.Manufacturer)\n",
    "            \n",
    "                    if area > min_area:\n",
    "                        AS_weight = AS_weight_calc(np.ones_like(tmp_array), tmp_array)\n",
    "                        AS = area * AS_weight\n",
    "                        AS_slice += AS       \n",
    "                \n",
    "                        \n",
    "            AS_D100 += AS_slice\n",
    "            BAS_D100[index] = AS_slice\n",
    "                \n",
    "        qc['AS'] = round(AS_D100,5)\n",
    "        qc['BAS_D100'] = BAS_D100\n",
    "        # To be done: exclude masked CAC from mean / SD calculation\n",
    "        # qc['mean'] = round(array_BAS_D100.mean(),5)\n",
    "        # qc['SD'] = round(array_BAS_D100.std(),5)\n",
    "    \n",
    "    # Calculate NPS\n",
    "    if phantom == \"CCI\":\n",
    "        #qc['NPS'] = nps_calc(array, num_ROIs = 1, rad = 32, ROI_size = 58, plot_NPS = False)\n",
    "        qc['NPS'] = nps_calc(array, num_ROIs = 18, rad = 32, ROI_size = 15, plot_NPS = False)\n",
    "    elif phantom == \"arteries\":\n",
    "        #qc['NPS'] = nps_calc(array, num_ROIs = 13, rad = 29, ROI_size = 13, plot_NPS = False)\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    if phantom == \"CCI\":\n",
    "        # calculate MTF\n",
    "        # qc['MTF'], qc['MTF0.5'] = mtf_calc(dcm_array[:,:,CCI_slice],\\\n",
    "        #               calc_size_density_VS_AS_MS['Large_HD'][0])\n",
    "        \n",
    "        # add in missing means\n",
    "        if 'Large_HD' not in calc_mean_dict.keys():\n",
    "            calc_mean_dict['Large_HD'] = 0\n",
    "        elif 'Large_MD' not in calc_mean_dict.keys():\n",
    "            calc_mean_dict['Large_MD'] = 0    \n",
    "        elif 'Large_LD' not in calc_mean_dict.keys():\n",
    "            calc_mean_dict['Large_LD'] = 0\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        # Calculate SNR\n",
    "        try:\n",
    "            qc['SNR_HD'] = calc_mean_dict['Large_HD'] / qc['SD']\n",
    "            qc['SNR_MD'] = calc_mean_dict['Large_MD'] / qc['SD']\n",
    "            qc['SNR_LD'] = calc_mean_dict['Large_LD'] / qc['SD']\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Calculate CNR\n",
    "        try:\n",
    "            qc['CNR_HD'] = abs(calc_mean_dict['Large_HD'] - qc['mean']) / qc['SD']\n",
    "            qc['CNR_MD'] = abs(calc_mean_dict['Large_MD'] - qc['mean']) / qc['SD']\n",
    "            qc['CNR_LD'] = abs(calc_mean_dict['Large_LD'] - qc['mean']) / qc['SD']\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    elif phantom == \"arteries\":\n",
    "        loc_calc1 = calc1[0] + int((calc1[1] - calc1[0])/2)\n",
    "        loc_calc2 = calc2[0] + int((calc2[1] - calc2[0])/2)\n",
    "        \n",
    "        qc['mean_calc1'] = round(np.sum(calcium_image[:,:,loc_calc1]) / np.count_nonzero(calcium_image[:,:,loc_calc1]),5)  \n",
    "        qc['mean_calc2'] = round(np.sum(calcium_image[:,:,loc_calc2]) / np.count_nonzero(calcium_image[:,:,loc_calc2]),5)  \n",
    "        \n",
    "        qc['SNR_calc1'] = round(qc['mean_calc1'] / qc['SD'],5)\n",
    "        qc['SNR_calc2'] = round(qc['mean_calc2'] / qc['SD'],5)\n",
    "        \n",
    "        qc['CNR_calc1'] = abs(qc['mean_calc1'] - qc['mean']) / qc['SD']\n",
    "        qc['CNR_calc2'] = abs(qc['mean_calc2'] - qc['mean']) / qc['SD']\n",
    "        \n",
    "    else: \n",
    "        pass\n",
    "        \n",
    "    # Calculate NTD\n",
    "    num_out_3SD = 0\n",
    "    for voxel in array.flatten():\n",
    "        test_value = abs(voxel - qc['mean'])\n",
    "        if test_value >= (qc['SD'] * 3):\n",
    "            num_out_3SD += 1\n",
    "    qc['NTD'] = num_out_3SD / (array.shape[0] * array.shape[1])\n",
    "        \n",
    "    # Calculate NPS peak\n",
    "    if phantom == \"CCI\":\n",
    "        qc['NPS_peak'] = qc['NPS'][0][np.where(qc['NPS'][1] == (qc['NPS'][1].max()))[0][0]]\n",
    "    \n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "18177837",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_centers(output, tmp_center, CCI_array):\n",
    "    sizes = []\n",
    "    for size_index in range(1,len(output[2])):\n",
    "        sizes.append(output[2][size_index][4])\n",
    "\n",
    "    largest = {}\n",
    "    for index in range(1,len(output[3])):\n",
    "        dist_loc = math.sqrt((tmp_center[1] - output[3][index][0])**2 +\\\n",
    "                             (tmp_center[0] - output[3][index][1])**2)\n",
    "        dist_loc *= header.PixelSpacing[0]\n",
    "        if dist_loc > 31:\n",
    "            largest[index] = [int(output[3][index][1]),int(output[3][index][0])]\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    max_dict = {}\n",
    "    for key in largest.keys():\n",
    "        tmp_arr = create_circular_mask(header.Rows, header.Columns,\\\n",
    "                                       [largest[key][1],largest[key][0]],\\\n",
    "                                       math.ceil(2.5 / header.PixelSpacing[0]))\n",
    "        tmp_arr = tmp_arr * dcm_array[:,:,CCI_slice] +\\\n",
    "                    tmp_arr * dcm_array[:,:,CCI_slice - 1] +\\\n",
    "                    tmp_arr * dcm_array[:,:,CCI_slice + 1]\n",
    "        tmp_arr[tmp_arr == 0] = np.nan\n",
    "        max_dict[key] = np.nanmedian(tmp_arr)\n",
    "\n",
    "    large1_index, large1_key = max(zip(max_dict.values(), max_dict.keys()))\n",
    "    max_dict.pop(large1_key)\n",
    "    large2_index, large2_key = max(zip(max_dict.values(), max_dict.keys()))\n",
    "    max_dict.pop(large2_key)\n",
    "    large3_index, large3_key = max(zip(max_dict.values(), max_dict.keys()))\n",
    "\n",
    "    center1 = largest[large1_key]\n",
    "    center2 = largest[large2_key]  \n",
    "    center3 = largest[large3_key]       \n",
    "\n",
    "    global center\n",
    "    center = findCircle(center1, center2, center3)\n",
    "    \n",
    "    \n",
    "    centers = {}\n",
    "    for size_index4 in (center1, center2, center3):\n",
    "        center_index = size_index4\n",
    "        side_x = abs(center[0]-center_index[0])\n",
    "        side_y = abs(center[1]-center_index[1])\n",
    "        \n",
    "        angle = angle_calc(side_x, side_y)\n",
    "        if (center_index[0] < center[0] and center_index[1] < center[1]):\n",
    "                medium_calc = [int(center_index[0] + (12.5 / header.PixelSpacing[0]) * math.sin(angle)),\\\n",
    "                               int((center_index[1] + (12.5 / header.PixelSpacing[1]) * math.cos(angle)))]\n",
    "            \n",
    "                low_calc = [int(center_index[0] + (25 / header.PixelSpacing[0]) * math.sin(angle)),\\\n",
    "                            int((center_index[1] + (25 / header.PixelSpacing[1]) * math.cos(angle)))]\n",
    "        elif (center_index[0] < center[0] and center_index[1] > center[1]):\n",
    "                medium_calc = [int(center_index[0] + (12.5 / header.PixelSpacing[0]) * math.sin(angle)),\\\n",
    "                               int((center_index[1] - (12.5 / header.PixelSpacing[1]) * math.cos(angle)))]\n",
    "            \n",
    "                low_calc = [int(center_index[0] + (25 / header.PixelSpacing[0]) * math.sin(angle)),\\\n",
    "                            int((center_index[1] - (25 / header.PixelSpacing[1]) * math.cos(angle)))] \n",
    "        elif (center_index[0] > center[0] and center_index[1] < center[1]):\n",
    "                medium_calc = [int(center_index[0] - (12.5 / header.PixelSpacing[0]) * math.sin(angle)),\\\n",
    "                               int((center_index[1] + (12.5 / header.PixelSpacing[1]) * math.cos(angle)))]\n",
    "            \n",
    "                low_calc = [int(center_index[0] - (25 / header.PixelSpacing[0]) * math.sin(angle)),\\\n",
    "                            int((center_index[1] + (25 / header.PixelSpacing[1]) * math.cos(angle)))]\n",
    "        elif (center_index[0] > center[0] and center_index[1] > center[1]):\n",
    "                medium_calc = [int(center_index[0] - (12.5 / header.PixelSpacing[0]) * math.sin(angle)),\\\n",
    "                               int((center_index[1] - (12.5 / header.PixelSpacing[1]) * math.cos(angle)))]\n",
    "            \n",
    "                low_calc = [int(center_index[0] - (25 / header.PixelSpacing[0]) * math.sin(angle)),\\\n",
    "                            int((center_index[1] - (25 / header.PixelSpacing[1]) * math.cos(angle)))]\n",
    "        elif (side_x == 0 and center_index[1] < center[1]):\n",
    "                medium_calc = [int(center_index[0]), int(center_index[1] + (12.5 / header.PixelSpacing[1]))]\n",
    "            \n",
    "                low_calc = [int(center_index[0]), int(center_index[1] + (25 / header.PixelSpacing[1]))]\n",
    "        elif (side_x == 0 and center_index[1] > center[1]):\n",
    "                medium_calc = [int(center_index[0]), int(center_index[1] - (12.5 / header.PixelSpacing[1]))]\n",
    "            \n",
    "                low_calc = [int(center_index[0]), int(center_index[1] - (25 / header.PixelSpacing[1]))]\n",
    "        elif (center_index[0] > center[0] and side_y == 0):\n",
    "                medium_calc = [int(center_index[0] - (12.5 / header.PixelSpacing[0])), int(center_index[1])]\n",
    "            \n",
    "                low_calc = [int(center_index[0] - (25 / header.PixelSpacing[0])), int(center_index[1])]\n",
    "        elif (center_index[0] > center[0] and side_y == 0):\n",
    "                medium_calc = [int(center_index[0] + (12.5 / header.PixelSpacing[0])), int(center_index[1])]\n",
    "            \n",
    "                low_calc = [int(center_index[0] + (25 / header.PixelSpacing[0])), int(center_index[1])]\n",
    "        else:\n",
    "                print(\"unknown angle.. error!\")\n",
    "                \n",
    "        if size_index4 == center1:\n",
    "            centers['Large_HD'] = ([center_index])\n",
    "            centers['Medium_HD'] = ([medium_calc])\n",
    "            centers['Small_HD'] = ([low_calc])            \n",
    "        \n",
    "        elif size_index4 == center2:\n",
    "            centers['Large_MD'] = ([center_index])\n",
    "            centers['Medium_MD'] = ([medium_calc])\n",
    "            centers['Small_MD'] = ([low_calc])    \n",
    "        \n",
    "        elif size_index4 == center3:\n",
    "            centers['Large_LD'] = ([center_index])\n",
    "            centers['Medium_LD'] = ([medium_calc])\n",
    "            centers['Small_LD'] = ([low_calc])   \n",
    "        \n",
    "        else:\n",
    "            pass\n",
    "    \n",
    "    return centers\n",
    "\n",
    "def ESF_logistic(ESF, mean_bottom, mean_top, header, factor):\n",
    "    def Fermi_func(x, d, a1, a2, a3, b1, b2, b3, c1, c2, c3):\n",
    "        return d + (a1 / (np.exp((x - b1)/c1) + 1)) +\\\n",
    "            (a2 / (np.exp((x - b2)/c2) + 1)) +\\\n",
    "                (a3 / (np.exp((x - b3)/c3) + 1))\n",
    "\n",
    "    A = mean_bottom\n",
    "    B = mean_top\n",
    "    R = len(ESF) / 2\n",
    "    d = A\n",
    "    a1 = 0.75*(B-A)\n",
    "    a2 = 0.125*(B-A)\n",
    "    a3 = 0.125*(B-A)\n",
    "    b1 = R\n",
    "    b2 = R - 0.5\n",
    "    b3 = R - 0.5\n",
    "    c1 = 0.15\n",
    "    c2 = 0.14\n",
    "    c3 = 0.14\n",
    "    \n",
    "    pixels = np.arange(0,len(ESF))\n",
    "    \n",
    "    params, params_covariance = optimize.curve_fit(Fermi_func, pixels, ESF,\n",
    "                                                p0=[d, a1, a2, a3, b1,\\\n",
    "                                                    b2, b3, c1, c2, c3],\\\n",
    "                                                    method = 'lm', maxfev = 50000)\n",
    "    \n",
    "    ESF = []\n",
    "    for element in pixels:\n",
    "        output = Fermi_func(element, params[0], params[1],\\\n",
    "                            params[2], params[3], params[4],\\\n",
    "                            params[5], params[6],\\\n",
    "                            params[7], params[8], params[9])\n",
    "        # print(element, output)\n",
    "        ESF.append(output)\n",
    "    \n",
    "    return ESF, pixels\n",
    "\n",
    "\n",
    "def ESF_logistic_one_function(ESF, mean_bottom, mean_top, header, factor):\n",
    "    def Fermi_func2(x, d, a, b, c):\n",
    "        return d + (a / (np.exp((x - b)/c) + 1))\n",
    "\n",
    "    A = mean_bottom\n",
    "    B = mean_top\n",
    "    R = len(ESF) / 2\n",
    "    d = A\n",
    "    a = 0.75*(B-A)\n",
    "    b = R\n",
    "    c = 0.15\n",
    "    \n",
    "    pixels = np.arange(0,len(ESF))\n",
    "    \n",
    "    params, params_covariance = optimize.curve_fit(Fermi_func2, pixels, ESF,\n",
    "                                                p0=[d, a, b, c],\\\n",
    "                                                    method = 'lm', maxfev = 50000)\n",
    "    \n",
    "    ESF = []\n",
    "    for element in pixels:\n",
    "        output = Fermi_func2(element, params[0], params[1], params[2], params[3])\n",
    "        # print(element, output)\n",
    "        ESF.append(output)\n",
    "    \n",
    "    return ESF, pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d7261375",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MTF_200mgHA(plot_MTF = False):\n",
    "    select_slice = CCI_slice + (flipped * int(35 / header.SliceThickness))\n",
    "    factor = 6\n",
    "    interpol_pixelspacing = header.PixelSpacing[0] / factor\n",
    "\n",
    "    array_int = interp_2D(dcm_array[:,:,select_slice], factor, interp_type = 'linear').copy()\n",
    "    array_binary = array_int.copy()\n",
    "    array_binary[array_binary < 1.2*calcium_threshold] = 0\n",
    "    array_binary[array_binary > 0] = 1\n",
    "    array_binary = array_binary.astype(dtype = np.uint8)    \n",
    "\n",
    "    output = cv2.connectedComponentsWithStats(array_binary, 4, cv2.CV_32S)\n",
    "    sizes = []\n",
    "    for index in range(1,output[0]):\n",
    "        sizes.append(output[2][index][4])\n",
    "        \n",
    "    center_index = sizes.index(max(sizes)) + 1\n",
    "\n",
    "    center_updated = [int(output[3][center_index][1]), int(output[3][center_index][0])]\n",
    "\n",
    "    \n",
    "    x_y_size = math.ceil(21 / interpol_pixelspacing)\n",
    "    array_200mgHA = np.zeros([x_y_size * 2 + 1, x_y_size* 2 + 1])\n",
    "\n",
    "    array_200mgHA = array_int[center_updated[0] - x_y_size:center_updated[0] + x_y_size + 1,\\\n",
    "                               center_updated[1] - x_y_size:center_updated[1] + x_y_size + 1]\n",
    "        \n",
    "    angles = list(range(360))\n",
    "    non_used_angles = list(range(int(angle_0_200HA - 45), int(angle_0_200HA + 45)))\n",
    "    used_angles = [used_angle for used_angle in angles if used_angle not in non_used_angles]    \n",
    "    ESF = [0]\n",
    "    for index in used_angles:\n",
    "        tmp_array = array_200mgHA.copy()\n",
    "        tmp_array = rotate(tmp_array,index)\n",
    "        new_ESF = tmp_array[x_y_size + 1,0:x_y_size + 1]\n",
    "        if len(ESF) == 1:\n",
    "            ESF = new_ESF\n",
    "        else:\n",
    "            ESF += new_ESF\n",
    "    ESF = ESF / len(used_angles)\n",
    "    \n",
    "    # plt.plot(ESF)\n",
    "    \n",
    "    #ESF, ESF_x = ESF_logistic(ESF, quality_output['mean'], Cal_rod_mean[2], header, factor)\n",
    "    ESF, ESF_x = ESF_logistic_one_function(ESF, quality_output['mean'], Cal_rod_mean[2], header, factor)\n",
    "    \n",
    "    # plt.scatter(ESF_x, ESF)\n",
    "    # plt.show()\n",
    "    \n",
    "    LSF = np.abs(np.diff(ESF))\n",
    "    LSF = LSF*np.hanning(len(LSF))\n",
    "    MTF = np.abs(np.fft.fft(LSF)) / sum(LSF)\n",
    "    \n",
    "    MTF_y = MTF[:int(len(LSF)/2)]\n",
    "    MTF_x = np.linspace(0, 1 / interpol_pixelspacing, len(LSF))\n",
    "    MTF_x = MTF_x[:int(len(LSF)/2)] \n",
    "    \n",
    "    MTF = [MTF_x, MTF_y]\n",
    "    \n",
    "    MTF_0_5 = round(np.interp(0.5, np.flip(MTF_y,0), np.flip(MTF_x,0)),2)\n",
    "    MTF_0_1 = round(np.interp(0.1, np.flip(MTF_y,0), np.flip(MTF_x,0)),2)\n",
    "    \n",
    "    if plot_MTF:\n",
    "        plt.plot(MTF[0], MTF[1])\n",
    "        plt.xlim(0,1.2)\n",
    "        plt.ylim(0,1)\n",
    "        plt.show()\n",
    "        print(\"\\nMTF_0.5 = \", MTF_0_5)\n",
    "        print(\"MTF_0.1 = \", MTF_0_1)\n",
    "        \n",
    "    return MTF, MTF_0_5, ESF\n",
    "\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "\n",
    "def intersect_mtlb(a, b):\n",
    "    a1, ia = np.unique(a, return_index=True)\n",
    "    b1, ib = np.unique(b, return_index=True)\n",
    "    aux = np.concatenate((a1, b1))\n",
    "    aux.sort()\n",
    "    c = aux[:-1][aux[1:] == aux[:-1]]\n",
    "    return c, ia[np.isin(a1, c)], ib[np.isin(b1, c)]\n",
    "\n",
    "\n",
    "def MTF_200mgHA_v2(plot_MTF = False):\n",
    "    # selection of image data\n",
    "    # average of three slices\n",
    "    x_y_size = math.ceil(21 / header.PixelSpacing[0])\n",
    "    select_slice = CCI_slice + (flipped * int(35 / header.SliceThickness))\n",
    "    array_200mgHA = np.zeros([x_y_size * 2 + 1, x_y_size* 2 + 1])\n",
    "    \n",
    "    for index in range(select_slice - 2, select_slice + 3):\n",
    "        array_200mgHA += dcm_array[center[0] - x_y_size:center[0] + x_y_size + 1,\\\n",
    "                              center[1] - x_y_size:center[1] + x_y_size + 1, index]\n",
    "            \n",
    "    array_200mgHA = array_200mgHA / 5\n",
    "\n",
    "    # normalisation of data\n",
    "    norm_array = array_200mgHA.copy()\n",
    "    norm_array = (norm_array - quality_output['mean']) / (Cal_rod_mean[2] - quality_output['mean'])\n",
    "    norm_array[norm_array > 1] = 1\n",
    "    norm_array[norm_array < 0] = 0\n",
    "    \n",
    "    \n",
    "    array_binary = array_200mgHA.copy()\n",
    "    array_binary[array_binary < calcium_threshold] = 0\n",
    "    array_binary[array_binary > 0] = 1\n",
    "    array_binary = array_binary.astype(dtype = np.uint8)\n",
    "    \n",
    "    output = cv2.connectedComponentsWithStats(array_binary, comp_connect, cv2.CV_32S)\n",
    "    center_updated = output[3][1]\n",
    "    \n",
    "    xaxis = (np.arange(x_y_size*2+1) - center_updated[0]) * header.PixelSpacing[0]\n",
    "    yaxis = (np.arange(x_y_size*2+1) - center_updated[1]) * header.PixelSpacing[1]\n",
    "    \n",
    "    r = np.zeros_like(array_200mgHA)\n",
    "    th = np.zeros_like(r)\n",
    "        \n",
    "    for i in range(r.shape[0]):\n",
    "        for j in range(r.shape[1]):\n",
    "            [r[j,i], th[j,i]] = cart2pol(xaxis[i], yaxis[j])\n",
    "\n",
    "    rstep=1\n",
    "    rbins = np.arange(0,r.max()+rstep,rstep)\n",
    "    \n",
    "    ESF = []\n",
    "    for r_size in rbins:\n",
    "        tmp_arr = r.copy()\n",
    "        tmp_arr = (tmp_arr >= r_size) & (tmp_arr < (r_size + rstep))\n",
    "        \n",
    "        esf_tmp = (norm_array * tmp_arr).sum() / np.count_nonzero(tmp_arr)\n",
    "        \n",
    "        ESF = np.append(ESF, esf_tmp)\n",
    "    \n",
    "    LSF = np.abs(np.diff(ESF))\n",
    "    \n",
    "    plt.plot(LSF)\n",
    "    plt.show()\n",
    "    \n",
    "    #LSF = LSF*np.hanning(x_y_size)   \n",
    "    \n",
    "    MTF = np.abs(np.fft.fft(LSF)) / sum(LSF)\n",
    "    MTF_x = np.linspace(0, len(MTF), len(MTF))\n",
    "    MTF_y = MTF[:int(len(LSF)/2)]\n",
    "    MTF_x = MTF_x[:int(len(LSF)/2)]\n",
    "    MTF = [MTF_x, MTF_y]\n",
    "\n",
    "    if plot_MTF:\n",
    "        plt.plot(MTF[0], MTF[1])\n",
    "        plt.show()\n",
    "        \n",
    "    plt.plot(MTF[0], MTF[1])\n",
    "    plt.show()\n",
    "    #MTF_0_5 = np.interp(0.5, np.flip(MTF_y,0), np.flip(MTF_x,0))\n",
    "\n",
    "    return MTF\n",
    "\n",
    "\n",
    "def mass_calibration(calc_size_density_VS_AS_MS, CCI_array):\n",
    "    # Calculate mass calibration factor\n",
    "    center_LD = [calc_size_density_VS_AS_MS['Large_LD'][0][0],\\\n",
    "                 calc_size_density_VS_AS_MS['Large_LD'][0][1]]\n",
    "\n",
    "    \n",
    "    dist_x = abs(center_LD[0] - center[0])\n",
    "    dist_y = abs(center_LD[1] - center[1])\n",
    "\n",
    "    if dist_x == 0:\n",
    "         mass_center_x = center[0]\n",
    "         if center_LD[1] > center[1]:\n",
    "             mass_center_y = math.ceil(center[1] - math.ceil(23 / header.PixelSpacing[0]))\n",
    "         else:\n",
    "             mass_center_y = math.ceil(center[1] + math.ceil(23 / header.PixelSpacing[0]))\n",
    "    elif dist_y == 0:\n",
    "        mass_center_y = center[1]\n",
    "        if center_LD[0] > center[0]:\n",
    "             mass_center_x = math.ceil(center[0] - math.ceil(23 / header.PixelSpacing[0]))\n",
    "        else:\n",
    "             mass_center_x = math.ceil(center[0] + math.ceil(23 / header.PixelSpacing[0]))\n",
    "    \n",
    "    else:\n",
    "        mass_angle = math.atan(dist_y / dist_x)\n",
    "        dist_x = (23 / header.PixelSpacing[0]) * math.cos(mass_angle)\n",
    "        dist_y = (23 / header.PixelSpacing[0]) * math.sin(mass_angle)\n",
    "    \n",
    "        if (center_LD[0] < center[0] and center_LD[1] < center[1]):\n",
    "            mass_center_x = math.ceil(center[0] + dist_x)\n",
    "            mass_center_y = math.ceil(center[1] + dist_y)\n",
    "        elif (center_LD[0] < center[0] and center_LD[1] > center[1]):\n",
    "            mass_center_x = math.ceil(center[0] + dist_x)\n",
    "            mass_center_y = math.ceil(center[1] - dist_y)\n",
    "        elif (center_LD[0] > center[0] and center_LD[1] < center[1]):\n",
    "            mass_center_x = math.ceil(center[0] - dist_x)\n",
    "            mass_center_y = math.ceil(center[1] + dist_y)\n",
    "        elif (center_LD[0] > center[0] and center_LD[1] > center[1]):\n",
    "            mass_center_x = math.ceil(center[0] - dist_x)\n",
    "            mass_center_y = math.ceil(center[1] - dist_y)\n",
    "        \n",
    "    mass_cal_center = [mass_center_y, mass_center_x]\n",
    "    \n",
    "    x_distance = abs(center[0] - mass_cal_center[1])\n",
    "    angled_distance = math.sqrt((center[0] - mass_cal_center[1])**2 +\\\n",
    "                                (center[1] - mass_cal_center[0])**2)\n",
    "    angle_0_200HA = math.acos(x_distance / angled_distance) * 180 / math.pi\n",
    "\n",
    "    mask_0HU = create_circular_mask(header.Columns, header.Rows,\\\n",
    "                                    mass_cal_center, int(6.9/ header.PixelSpacing[0]))\n",
    "    \n",
    "    masked_0HU = mask_0HU * dcm_array[:,:,cal_rod_slice]\n",
    "    mean_0HU = masked_0HU.sum() / np.count_nonzero(masked_0HU)\n",
    "    \n",
    "    std_0HU = 0\n",
    "    for voxel in masked_0HU.flatten():\n",
    "        if voxel != 0:\n",
    "            std_0HU += (voxel - mean_0HU)**2\n",
    "    std_0HU = math.sqrt(std_0HU / np.count_nonzero(masked_0HU))\n",
    "    \n",
    "    mask_200HU = create_circular_mask(header.Columns, header.Rows,\\\n",
    "                                      [center[1], center[0]], int(6.9/ header.PixelSpacing[0]))\n",
    "    \n",
    "    masked_200HU = mask_200HU * dcm_array[:,:,cal_rod_slice]\n",
    "    mean_200HU = masked_200HU.sum() / np.count_nonzero(masked_200HU)\n",
    "    \n",
    "    mass_cal_factor = 0.2 / (mean_200HU - mean_0HU)\n",
    "    \n",
    "    water_rod_metrics = [mean_0HU, std_0HU]\n",
    "  \n",
    "    return mass_cal_factor, angle_0_200HA, water_rod_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cded93c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_mean_calculator(calc_dict_tmp, key_calc_dict, arr_mean, ML_array, slice_ind):\n",
    "    arr_mean[arr_mean != slice_ind] = 0\n",
    "    arr_mean[arr_mean == slice_ind] = 1\n",
    "    tmp_mean_arr = arr_mean * ML_array\n",
    "   \n",
    "    mean_tmp = tmp_mean_arr.sum() \n",
    "    mean_count = np.count_nonzero(tmp_mean_arr)\n",
    "    \n",
    "    try:\n",
    "        calc_dict_tmp[key_calc_dict][0] += mean_tmp\n",
    "        calc_dict_tmp[key_calc_dict][1] += mean_count\n",
    "            \n",
    "    except:\n",
    "        calc_dict_tmp[key_calc_dict] = [mean_tmp, mean_count]\n",
    "\n",
    "    return calc_dict_tmp\n",
    "\n",
    "\n",
    "def SNR_dict_calculutor(SNR_dict_tmp, key_SNR_dict, arr_mean, ML_array, slice_ind):\n",
    "    arr_mean[arr_mean != slice_ind] = 0\n",
    "    arr_mean[arr_mean == slice_ind] = 1\n",
    "    tmp_mean_arr = arr_mean * ML_array\n",
    "    \n",
    "    SNR_dict_tmp[key_SNR_dict] = tmp_mean_arr.sum() / np.count_nonzero(tmp_mean_arr)\n",
    "    \n",
    "    return SNR_dict_tmp\n",
    "\n",
    "\n",
    "\n",
    "def CCI_scoring(print_plot = False):\n",
    "    # Actual scoring for CCI insert\n",
    "    # First step is to remove slices without calcium from arrays            \n",
    "    CCI_min = int((CCI_slice - math.ceil(5 / header.SliceThickness)) - 1)\n",
    "    CCI_max = int((CCI_slice + math.ceil(5 / header.SliceThickness)) + 1)\n",
    "    central_CCI = int((CCI_max - CCI_min)/2)\n",
    "    \n",
    "    if CCI_min < 0:\n",
    "        CCI_min = 0\n",
    "    if CCI_max > dcm_array.shape[2]:\n",
    "        CCI_max = dcm_array.shape[2]\n",
    "    \n",
    "    CCI_array = dcm_array[:,:,CCI_min:CCI_max].copy()\n",
    "    \n",
    "    CCI_array_binary = CCI_array.copy()\n",
    "    CCI_array_binary[CCI_array_binary < 1.0*calcium_threshold] = 0\n",
    "    CCI_array_binary[CCI_array_binary > 0] = 1\n",
    "    CCI_array_binary = CCI_array_binary.astype(dtype = np.uint8)\n",
    "    \n",
    "    _, _, _, centroids = cv2.connectedComponentsWithStats(CCI_array_binary[:,:,central_CCI - 1] +\\\n",
    "                                                          CCI_array_binary[:,:,central_CCI] +\\\n",
    "                                                          CCI_array_binary[:,:,central_CCI + 1],\\\n",
    "                                                          comp_connect,cv2.CV_32S)\n",
    "    \n",
    "    centroids = np.delete(centroids,0,0)\n",
    "    \n",
    "    CCI_Agatston_scores = {}\n",
    "    CCI_Volume_scores = {}\n",
    "    for index in range(len(centroids)):\n",
    "        CCI_Agatston_scores[index] = 0\n",
    "        CCI_Volume_scores[index] = 0\n",
    "\n",
    "    image_kernel = math.ceil(3 / header.PixelSpacing[0])\n",
    "    if image_kernel % 2 == 0:\n",
    "        image_kernel += 1\n",
    "        \n",
    "    image_for_center = scipy.signal.medfilt2d(CCI_array_binary[:,:,central_CCI - 1], image_kernel) +\\\n",
    "                       scipy.signal.medfilt2d(CCI_array_binary[:,:,central_CCI], image_kernel) +\\\n",
    "                       scipy.signal.medfilt2d(CCI_array_binary[:,:,central_CCI + 1], image_kernel)\n",
    "                       \n",
    "    # plt.imshow(image_for_center)\n",
    "    # plt.show()\n",
    "    # plt.imshow(image_for_center, cmap='bone')\n",
    "    # plt.xticks(fontsize = 35)\n",
    "    # plt.yticks(fontsize = 35)\n",
    "    # plt.show()\n",
    "    \n",
    "    output = cv2.connectedComponentsWithStats(image_for_center, comp_connect,cv2.CV_32S)\n",
    "\n",
    "    tmp_center = center.copy()\n",
    "    calc_size_density_VS_AS_MS = calc_centers(output, tmp_center, CCI_array)\n",
    "\n",
    "    mass_cal_factor, angle_0_200HA, water_rod_metrics = mass_calibration(calc_size_density_VS_AS_MS, CCI_array)\n",
    "        \n",
    "    for key in calc_size_density_VS_AS_MS.keys():\n",
    "        calc_size_density_VS_AS_MS[key].append(0)\n",
    "        calc_size_density_VS_AS_MS[key].append(0)\n",
    "        calc_size_density_VS_AS_MS[key].append(0)\n",
    "    \n",
    "    mask_L_HD = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Large_HD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Large_HD'][0][0]],math.ceil((5 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_L_MD = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Large_MD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Large_MD'][0][0]],math.ceil((5 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_L_LD = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Large_LD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Large_LD'][0][0]],math.ceil((5 / header.PixelSpacing[0])/2) + 1)   \n",
    "    mask_M_HD = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Medium_HD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Medium_HD'][0][0]],math.ceil((3 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_M_MD = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Medium_MD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Medium_MD'][0][0]],math.ceil((3 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_M_LD = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Medium_LD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Medium_LD'][0][0]],math.ceil((3 / header.PixelSpacing[0])/2) + 1) \n",
    "    mask_S_HD = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Small_HD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Small_HD'][0][0]],math.ceil((1 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_S_MD = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Small_MD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Small_MD'][0][0]],math.ceil((1 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_S_LD = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Small_LD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Small_LD'][0][0]],math.ceil((1 / header.PixelSpacing[0])/2) + 1) \n",
    "    \n",
    "    \n",
    "    masks1 = mask_L_HD + mask_M_HD + mask_S_HD\n",
    "    masks2 = mask_L_MD + mask_M_MD + mask_S_MD\n",
    "    masks3 = mask_L_LD + mask_M_LD + mask_S_LD\n",
    "\n",
    "    if print_plot:\n",
    "        plt.subplot(121)\n",
    "        plt.imshow(calcium_image[:,:,CCI_slice])\n",
    "        plt.subplot(122)\n",
    "        plt.imshow(masks1 + masks2 + masks3)\n",
    "        plt.show()\n",
    "    \n",
    "    mask_L_HD_BAS = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Large_HD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Large_HD'][0][0]],math.ceil((5*2 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_L_MD_BAS = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Large_MD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Large_MD'][0][0]],math.ceil((5*2 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_L_LD_BAS = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Large_LD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Large_LD'][0][0]],math.ceil((5*2 / header.PixelSpacing[0])/2) + 1)   \n",
    "    mask_M_HD_BAS = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Medium_HD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Medium_HD'][0][0]],math.ceil((3*2 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_M_MD_BAS = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Medium_MD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Medium_MD'][0][0]],math.ceil((3*2 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_M_LD_BAS = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Medium_LD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Medium_LD'][0][0]],math.ceil((3*2 / header.PixelSpacing[0])/2) + 1) \n",
    "    mask_S_HD_BAS = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Small_HD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Small_HD'][0][0]],math.ceil((1*2 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_S_MD_BAS = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Small_MD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Small_MD'][0][0]],math.ceil((1*2 / header.PixelSpacing[0])/2) + 1)\n",
    "    mask_S_LD_BAS = create_circular_mask(header.Columns, header.Rows, [calc_size_density_VS_AS_MS['Small_LD'][0][1],\\\n",
    "                       calc_size_density_VS_AS_MS['Small_LD'][0][0]],math.ceil((1*2 / header.PixelSpacing[0])/2) + 1) \n",
    "    \n",
    "    BAS_Mask = mask_L_HD_BAS + mask_M_HD_BAS + mask_S_HD_BAS+\\\n",
    "                  mask_L_MD_BAS + mask_M_MD_BAS + mask_S_MD_BAS+\\\n",
    "                      mask_L_LD_BAS + mask_M_LD_BAS + mask_S_LD_BAS\n",
    "                      \n",
    "    BAS_Mask = np.invert(BAS_Mask)\n",
    "        \n",
    "    # plt.imshow(masks1 + masks2 + masks3, cmap='bone')\n",
    "    # plt.xticks(fontsize = 35)\n",
    "    # plt.yticks(fontsize = 35)\n",
    "    # plt.show()\n",
    "    \n",
    "        \n",
    "    # Volume score calculation\n",
    "    if (Volume_score_calc and (header.Manufacturer == 'SIEMENS' or header.Manufacturer == 'Literature')):\n",
    "        #CCI_int_min = int(CCI_min * int_factor - int_factor / 2)\n",
    "        #CCI_int_max = int(CCI_max * int_factor + int_factor / 2)\n",
    "        #CCI_array_int = int_dcm_array[:,:,CCI_int_min:CCI_int_max]\n",
    "        \n",
    "        int_header, CCI_array_int = dcm_interpolation(dcm_array[:,:,CCI_min:CCI_max])\n",
    "        \n",
    "        CCI_array_int_binary = CCI_array_int.copy()\n",
    "        CCI_array_int_binary[CCI_array_int_binary < calcium_threshold] = 0\n",
    "        CCI_array_int_binary[CCI_array_int_binary > 0] = 1\n",
    "        CCI_array_int_binary = CCI_array_int_binary.astype(dtype = np.uint8)\n",
    "        for slice_index in range(CCI_array_int.shape[2]):\n",
    "            output = cv2.connectedComponentsWithStats(CCI_array_int_binary[:,:,slice_index],\\\n",
    "                                                          comp_connect, cv2.CV_32S)\n",
    "                \n",
    "            for slice_index2 in range(1,output[0]):\n",
    "                coordinates = int(output[3][slice_index2][1]), int(output[3][slice_index2][0])\n",
    "                area = output[2][slice_index2][4] * int_header.PixelSpacing[0]**2\n",
    "                \n",
    "                min_area = min_area_det(header.Manufacturer)\n",
    "                        \n",
    "                if area > min_area:\n",
    "                    VS = area * int_header.SliceThickness\n",
    "                    \n",
    "                    if mask_L_HD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Large_HD'][1] += VS\n",
    "                    elif mask_L_MD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Large_MD'][1] += VS                \n",
    "                    elif mask_L_LD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Large_LD'][1] += VS                                  \n",
    "                    elif mask_M_HD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Medium_HD'][1] += VS                     \n",
    "                    elif mask_M_MD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Medium_MD'][1] += VS                    \n",
    "                    elif mask_M_LD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Medium_LD'][1] += VS                \n",
    "                    elif mask_S_HD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Small_HD'][1] += VS                    \n",
    "                    elif mask_S_MD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Small_MD'][1] += VS                    \n",
    "                    elif mask_S_LD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Small_LD'][1] += VS\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "    \n",
    "    \n",
    "    CCI_array_binary = CCI_array.copy()\n",
    "    CCI_array_binary[CCI_array_binary < calcium_threshold] = 0\n",
    "    CCI_array_binary[CCI_array_binary > 0] = 1\n",
    "    CCI_array_binary = CCI_array_binary.astype(dtype = np.uint8)\n",
    "    \n",
    "    \n",
    "    calc_mean_dict = {}\n",
    "    SNR_dict = {}\n",
    "    # Agatston and Mass score calculation\n",
    "    for slice_index in range(CCI_array.shape[2]):\n",
    "        output = cv2.connectedComponentsWithStats(CCI_array_binary[:,:,slice_index],\\\n",
    "                                                      comp_connect, cv2.CV_32S)\n",
    "        \n",
    "            \n",
    "        for slice_index2 in range(1,output[0]):\n",
    "            coordinates = int(output[3][slice_index2][1]), int(output[3][slice_index2][0])\n",
    "            area = output[2][slice_index2][4] * header.PixelSpacing[0]**2\n",
    "            \n",
    "            mask_mean_mass = output[1].copy()\n",
    "            mask_mean_mass[mask_mean_mass != slice_index2] = 0\n",
    "            mask_mean_mass[mask_mean_mass != 0] = 1\n",
    "\n",
    "            min_area = min_area_det(header.Manufacturer)\n",
    "                    \n",
    "            if area > min_area:\n",
    "                MS = area * header.SliceThickness * mass_mean_def(mask_mean_mass * CCI_array[:,:,slice_index])\n",
    "                \n",
    "                if mask_L_HD[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_L_HD, CCI_array[:,:,slice_index])\n",
    "                    calc_size_density_VS_AS_MS['Large_HD'][2] += AS_weight * area\n",
    "                    \n",
    "                    calc_size_density_VS_AS_MS['Large_HD'][3] += MS                        \n",
    "                    calc_mean_dict = calc_mean_calculator(calc_mean_dict, 'Large_HD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                    \n",
    "                    if slice_index == central_CCI:\n",
    "                        SNR_dict = SNR_dict_calculutor(SNR_dict, 'Large_HD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)    \n",
    "                        \n",
    "\n",
    "                elif mask_L_MD[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_L_MD, CCI_array[:,:,slice_index])\n",
    "                    calc_size_density_VS_AS_MS['Large_MD'][2] += AS_weight * area\n",
    "                    \n",
    "                    calc_size_density_VS_AS_MS['Large_MD'][3] += MS                    \n",
    "                    calc_mean_dict = calc_mean_calculator(calc_mean_dict, 'Large_MD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                        \n",
    "                    if slice_index == central_CCI:\n",
    "                        SNR_dict = SNR_dict_calculutor(SNR_dict, 'Large_MD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                \n",
    "                elif mask_L_LD[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_L_LD, CCI_array[:,:,slice_index])\n",
    "                    calc_size_density_VS_AS_MS['Large_LD'][2] += AS_weight * area\n",
    "\n",
    "                    calc_size_density_VS_AS_MS['Large_LD'][3] += MS                     \n",
    "                    calc_mean_dict = calc_mean_calculator(calc_mean_dict, 'Large_LD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                        \n",
    "                                            \n",
    "                    if slice_index == central_CCI:\n",
    "                        SNR_dict = SNR_dict_calculutor(SNR_dict, 'Large_LD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                \n",
    "                elif mask_M_HD[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_M_HD, CCI_array[:,:,slice_index])\n",
    "                    calc_size_density_VS_AS_MS['Medium_HD'][2] += AS_weight * area\n",
    "\n",
    "                    calc_size_density_VS_AS_MS['Medium_HD'][3] += MS                    \n",
    "                    calc_mean_dict = calc_mean_calculator(calc_mean_dict, 'Medium_HD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                \n",
    "                elif mask_M_MD[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_M_MD, CCI_array[:,:,slice_index])\n",
    "                    calc_size_density_VS_AS_MS['Medium_MD'][2] += AS_weight * area\n",
    "                    \n",
    "                    calc_size_density_VS_AS_MS['Medium_MD'][3] += MS                     \n",
    "                    calc_mean_dict = calc_mean_calculator(calc_mean_dict, 'Medium_MD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "               \n",
    "                elif mask_M_LD[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_M_LD, CCI_array[:,:,slice_index])\n",
    "                    calc_size_density_VS_AS_MS['Medium_LD'][2] += AS_weight * area\n",
    "                    \n",
    "                    calc_size_density_VS_AS_MS['Medium_LD'][3] += MS  \n",
    "                    \n",
    "                    calc_mean_dict = calc_mean_calculator(calc_mean_dict, 'Medium_LD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                \n",
    "                elif mask_S_HD[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_S_HD, CCI_array[:,:,slice_index])\n",
    "                    calc_size_density_VS_AS_MS['Small_HD'][2] += AS_weight * area\n",
    "\n",
    "                    calc_size_density_VS_AS_MS['Small_HD'][3] += MS \n",
    "                    calc_mean_dict = calc_mean_calculator(calc_mean_dict, 'Small_HD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                \n",
    "                elif mask_S_MD[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_S_MD, CCI_array[:,:,slice_index])\n",
    "                    calc_size_density_VS_AS_MS['Small_MD'][2] += AS_weight * area\n",
    "                    \n",
    "                    calc_size_density_VS_AS_MS['Small_MD'][3] += MS\n",
    "                    calc_mean_dict = calc_mean_calculator(calc_mean_dict, 'Small_MD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                \n",
    "                elif mask_S_LD[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_S_LD, CCI_array[:,:,slice_index])\n",
    "                    calc_size_density_VS_AS_MS['Small_LD'][2] += AS_weight * area\n",
    "\n",
    "                    calc_size_density_VS_AS_MS['Small_LD'][3] += MS\n",
    "                    calc_mean_dict = calc_mean_calculator(calc_mean_dict, 'Small_LD', output[1].copy(),\\\n",
    "                                       CCI_array[:,:,slice_index].copy(), slice_index2)\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass\n",
    "      \n",
    "    if (header.Manufacturer == 'PHILIPS' or header.Manufacturer == 'CANON' or header.Manufacturer == 'GE'):\n",
    "        for key in calc_size_density_VS_AS_MS.keys():\n",
    "            calc_size_density_VS_AS_MS[key][1] = 0\n",
    "            calc_size_density_VS_AS_MS[key][3] = 0\n",
    "        \n",
    "        min_area = min_area_det(header.Manufacturer)\n",
    "        \n",
    "        CCI_array_binary = CCI_array.copy()\n",
    "        if header.Manufacturer == 'PHILIPS':\n",
    "            CCI_array_binary[CCI_array_binary < Philips_mass_score_threshold] = 0\n",
    "        else:\n",
    "            CCI_array_binary[CCI_array_binary < calcium_threshold] = 0\n",
    "        CCI_array_binary[CCI_array_binary > 0] = 1\n",
    "        CCI_array_binary = CCI_array_binary.astype(dtype = np.uint8)\n",
    "    \n",
    "             \n",
    "        # Volume and Mass score calculation\n",
    "        for slice_index in range(CCI_array.shape[2]):\n",
    "            output = cv2.connectedComponentsWithStats(CCI_array_binary[:,:,slice_index],\\\n",
    "                                                          comp_connect, cv2.CV_32S)\n",
    "            \n",
    "            for slice_index2 in range(1,output[0]):\n",
    "                coordinates = int(output[3][slice_index2][1]), int(output[3][slice_index2][0])\n",
    "                area = output[2][slice_index2][4] * header.PixelSpacing[0]**2 \n",
    "                \n",
    "                mask_mean_mass = output[1].copy()\n",
    "                mask_mean_mass[mask_mean_mass != slice_index2] = 0\n",
    "                mask_mean_mass[mask_mean_mass != 0] = 1\n",
    "\n",
    "                if area > min_area:\n",
    "                    MS = area * header.SliceThickness * mass_mean_def(mask_mean_mass * CCI_array[:,:,slice_index])\n",
    "                    VS = area * header.SliceThickness\n",
    "                    \n",
    "                    if mask_L_HD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Large_HD'][1] += VS\n",
    "                        calc_size_density_VS_AS_MS['Large_HD'][3] += MS \n",
    "                    elif mask_L_MD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Large_MD'][1] += VS\n",
    "                        calc_size_density_VS_AS_MS['Large_MD'][3] += MS  \n",
    "                    \n",
    "                    elif mask_L_LD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Large_LD'][1] += VS\n",
    "                        calc_size_density_VS_AS_MS['Large_LD'][3] += MS         \n",
    "                    \n",
    "                    elif mask_M_HD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Medium_HD'][1] += VS\n",
    "                        calc_size_density_VS_AS_MS['Medium_HD'][3] += MS  \n",
    "                    \n",
    "                    elif mask_M_MD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Medium_MD'][1] += VS\n",
    "                        calc_size_density_VS_AS_MS['Medium_MD'][3] += MS  \n",
    "                   \n",
    "                    elif mask_M_LD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Medium_LD'][1] += VS\n",
    "                        calc_size_density_VS_AS_MS['Medium_LD'][3] += MS               \n",
    "                    \n",
    "                    elif mask_S_HD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Small_HD'][1] += VS\n",
    "                        calc_size_density_VS_AS_MS['Small_HD'][3] += MS  \n",
    "                    \n",
    "                    elif mask_S_MD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Small_MD'][1] += VS\n",
    "                        calc_size_density_VS_AS_MS['Small_MD'][3] += MS   \n",
    "                    \n",
    "                    elif mask_S_LD[coordinates] != False:\n",
    "                        calc_size_density_VS_AS_MS['Small_LD'][1] += VS\n",
    "                        calc_size_density_VS_AS_MS['Small_LD'][3] += MS  \n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "       \n",
    "    for key in calc_size_density_VS_AS_MS.keys():\n",
    "        calc_size_density_VS_AS_MS[key][1] = round(calc_size_density_VS_AS_MS[key][1],5)\n",
    "        calc_size_density_VS_AS_MS[key][2] = round(calc_size_density_VS_AS_MS[key][2] * header.SliceThickness / 3,5)\n",
    "        calc_size_density_VS_AS_MS[key][3] = round(calc_size_density_VS_AS_MS[key][3] * mass_cal_factor,5)\n",
    "    \n",
    "    for key in calc_mean_dict.keys():\n",
    "        calc_mean_dict[key] = round(calc_mean_dict[key][0] / calc_mean_dict[key][1],5)\n",
    "        \n",
    "    return calc_size_density_VS_AS_MS, center, mass_cal_factor, calc_mean_dict, angle_0_200HA, water_rod_metrics, SNR_dict, BAS_Mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f766d58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AS_200mgHA(array_200mgHA, mask_used, threshold_used):\n",
    "    array_200mgHA_original = array_200mgHA.copy()\n",
    "    array_200mgHA_binary = array_200mgHA_original.copy()\n",
    "    array_200mgHA_binary[array_200mgHA_binary < threshold_used] = 0\n",
    "    array_200mgHA_binary[array_200mgHA_binary > 0] = 1\n",
    "    array_200mgHA_binary = array_200mgHA_binary.astype(dtype = np.uint8)\n",
    "    \n",
    "    array_200mgHA_binary = scipy.signal.medfilt2d(array_200mgHA_binary, 7)\n",
    "\n",
    "\n",
    "    output = cv2.connectedComponentsWithStats(array_200mgHA_binary, comp_connect, cv2.CV_32S)\n",
    "    \n",
    "    tmp_size_dict = {}\n",
    "    for index in range(1,output[0]):\n",
    "        tmp_size_dict[index] = output[2][index][4]\n",
    "    \n",
    "    _, comp_index = max(zip(tmp_size_dict.values(), tmp_size_dict.keys()))\n",
    "    \n",
    "    if mask_used:\n",
    "        mask = create_circular_mask(header.Columns, header.Rows,\\\n",
    "                                output[3][comp_index], int(6/ header.PixelSpacing[0]))\n",
    "    \n",
    "        array_200mgHA_binary    = mask * array_200mgHA_binary\n",
    "        array_200mgHA_original  = mask * array_200mgHA_original\n",
    "        \n",
    "        output = cv2.connectedComponentsWithStats(array_200mgHA_binary, comp_connect, cv2.CV_32S)\n",
    "    \n",
    "    cal_rod_array = output[1]\n",
    "    cal_rod_array[cal_rod_array!=comp_index] = 0\n",
    "    cal_rod_array[cal_rod_array!=0] = 1\n",
    "    \n",
    "    AS_weight = AS_weight_calc(cal_rod_array, array_200mgHA)\n",
    "    AS_calrod = round(AS_weight * cal_rod_array.sum() * header.PixelSpacing[0]**2,1)\n",
    "    \n",
    "    mean_calrod = round((cal_rod_array * array_200mgHA_original).sum() / np.count_nonzero(cal_rod_array),1)\n",
    "    return AS_calrod, mean_calrod\n",
    "\n",
    "\n",
    "def Measurement_calrod(array_200mgHA, masked_values = False):\n",
    "    # calculate mean and AS for calibration rod    \n",
    "    AS_VarHU_tot, mean_VarHU_tot = AS_200mgHA(array_200mgHA, False, calcium_threshold)\n",
    "    AS_130HU_tot, mean_130HU_tot = AS_200mgHA(array_200mgHA, False, 130)\n",
    "    if masked_values:\n",
    "        AS_130HU_small, mean_130HU_small = AS_200mgHA(array_200mgHA, True, calcium_threshold)\n",
    "        AS_VarHU_small, mean_VarHU_small = AS_200mgHA(array_200mgHA, True, 130)\n",
    "    else:\n",
    "        AS_130HU_small, mean_130HU_small = None, None\n",
    "        AS_VarHU_small, mean_VarHU_small = None, None\n",
    "    \n",
    "    Agatston_cal_rod    = [AS_130HU_small, AS_VarHU_small, AS_130HU_tot, AS_VarHU_tot]\n",
    "    Mean_cal_rod        = [mean_130HU_small, mean_VarHU_small, mean_130HU_tot, mean_VarHU_tot]\n",
    "    \n",
    "    return Agatston_cal_rod, Mean_cal_rod\n",
    "\n",
    "\n",
    "def write_CCI_to_excel(row_used, row_NPS, row_MTF, row_IQ, row_ESF):\n",
    "    used_data.write(0, 0, 'Phantom')\n",
    "    used_data.write(0, 1, 'Scan_description')\n",
    "    used_data.write(0, 2, 'Calcification')\n",
    "    used_data.write(0, 3, 'Volume score')\n",
    "    used_data.write(0, 4, 'Agatston score')\n",
    "    used_data.write(0, 5, 'Mass score')\n",
    "    used_data.write(0, 6, 'Mass calibration factor')\n",
    "    used_data.write(0, 7, 'mAs')\n",
    "    used_data.write(0, 8, 'kVp')\n",
    "    used_data.write(0, 9, 'SliceThickness')\n",
    "    used_data.write(0, 10, 'SliceIncrement')\n",
    "    used_data.write(0, 11, 'CTDIvol')\n",
    "    used_data.write(0, 12, 'Accessionnr')\n",
    "    used_data.write(0, 13, 'Path')\n",
    "    \n",
    "    \n",
    "    # sub_string = dcm_name.rsplit(root_path)[1][1:] #Canon\n",
    "    # sub_string2 = sub_string[:sub_string.find('\\\\')] #Siemens_force, Newport, GE\n",
    "    scan_name = dcm_name.rsplit('\\\\')[len(dcm_name.rsplit('\\\\'))-1]\n",
    "    # scan_name = scan_name + '_' + str(header.XRayTubeCurrent)\n",
    "    if 'CCI_Large' in dcm_name:\n",
    "        phantom = 'large'\n",
    "    elif 'CCI_small' in dcm_name:\n",
    "        phantom = 'small'\n",
    "    else:\n",
    "        phantom = 'unknown'\n",
    "    \n",
    "\n",
    "    exposure = header.Exposure\n",
    "\n",
    "    \n",
    "    for key in calc_size_density_VS_AS_MS.keys():\n",
    "        used_data.write(row_used, column, phantom)\n",
    "        used_data.write(row_used, column + 1, scan_name)\n",
    "        used_data.write(row_used, column + 2, key)\n",
    "        used_data.write(row_used, column + 3, calc_size_density_VS_AS_MS[key][1])\n",
    "        used_data.write(row_used, column + 4, calc_size_density_VS_AS_MS[key][2])\n",
    "        used_data.write(row_used, column + 5, calc_size_density_VS_AS_MS[key][3])\n",
    "        used_data.write(row_used, column + 6, mass_cal_factor * 1000)\n",
    "        try:\n",
    "            used_data.write(row_used, column + 7, exposure) #header.XRayTubeCurrent / header.Exposure\n",
    "        except:\n",
    "            pass\n",
    "        used_data.write(row_used, column + 8, header.KVP)\n",
    "        used_data.write(row_used, column + 9, slice_thick_ori)\n",
    "        try:\n",
    "            used_data.write(row_used, column + 10, header.SpacingBetweenSlices)\n",
    "        except:\n",
    "            try:\n",
    "                used_data.write(row_used, column + 10, header.SliceThickness)\n",
    "            except:\n",
    "                pass\n",
    "        used_data.write(row_used, column + 11, header.CTDIvol)\n",
    "        used_data.write(row_used, column + 12, header.AccessionNumber) \n",
    "        used_data.write(row_used, column + 13, dcm_name)\n",
    "\n",
    "        row_used += 1\n",
    "        \n",
    "    IQ_data.write(0, 0, 'Phantom')\n",
    "    IQ_data.write(0, 1, 'Scan_description')\n",
    "    IQ_data.write(0, 2, 'Background mean HU')\n",
    "    IQ_data.write(0, 3, 'Background SD')\n",
    "    IQ_data.write(0, 4, 'Background AS')\n",
    "    IQ_data.write(0, 5, 'Water_rod mean HU')\n",
    "    IQ_data.write(0, 6, 'Water_rod SD')\n",
    "    IQ_data.write(0, 7, 'MTF_0.5')\n",
    "    IQ_data.write(0, 8, 'SNR High density')\n",
    "    IQ_data.write(0, 9, 'SNR Medium density')\n",
    "    IQ_data.write(0, 10, 'SNR Low density')\n",
    "    IQ_data.write(0, 11, 'CNR High density')\n",
    "    IQ_data.write(0, 12, 'CNR Medium density')\n",
    "    IQ_data.write(0, 13, 'CNR Low density')\n",
    "    IQ_data.write(0, 14, 'NTD')\n",
    "    IQ_data.write(0, 15, 'NPS peak')\n",
    "    IQ_data.write(0, 16, 'Mean_L_HD')\n",
    "    IQ_data.write(0, 17, 'Mean_L_MD')\n",
    "    IQ_data.write(0, 18, 'Mean_L_LD')\n",
    "    IQ_data.write(0, 19, 'Mean_M_HD')\n",
    "    IQ_data.write(0, 20, 'Mean_M_MD')\n",
    "    IQ_data.write(0, 21, 'Mean_M_LD')\n",
    "    IQ_data.write(0, 22, 'Mean_S_HD')\n",
    "    IQ_data.write(0, 23, 'Mean_S_MD')\n",
    "    IQ_data.write(0, 24, 'Mean_S_LD')\n",
    "    IQ_data.write(0, 25, 'Recon')\n",
    "    \n",
    "    \n",
    "    IQ_data.write(row_IQ, column, phantom)\n",
    "    IQ_data.write(row_IQ, column + 1, scan_name)\n",
    "    IQ_data.write(row_IQ, column + 2, quality_output['mean'])\n",
    "    IQ_data.write(row_IQ, column + 3, quality_output['SD'])\n",
    "    IQ_data.write(row_IQ, column + 4, quality_output['AS'])\n",
    "    IQ_data.write(row_IQ, column + 5, water_rod[0])\n",
    "    IQ_data.write(row_IQ, column + 6, water_rod[1])\n",
    "    try:\n",
    "        IQ_data.write(row_IQ, column + 7, quality_output['MTF0.5'])\n",
    "        IQ_data.write(row_IQ, column + 8, quality_output['SNR_HD'])\n",
    "        IQ_data.write(row_IQ, column + 9, quality_output['SNR_MD'])\n",
    "        IQ_data.write(row_IQ, column + 10, quality_output['SNR_LD'])\n",
    "    except:\n",
    "        pass\n",
    "    try:\n",
    "        IQ_data.write(row_IQ, column + 11, quality_output['CNR_HD'])\n",
    "        IQ_data.write(row_IQ, column + 12, quality_output['CNR_MD'])\n",
    "        IQ_data.write(row_IQ, column + 13, quality_output['CNR_LD'])\n",
    "    except:\n",
    "        pass\n",
    "    IQ_data.write(row_IQ, column + 14, quality_output['NTD'])\n",
    "    IQ_data.write(row_IQ, column + 15, quality_output['NPS_peak'])\n",
    "    try:\n",
    "        IQ_data.write(row_IQ, column + 16, calc_mean_dict['Large_HD'])\n",
    "        IQ_data.write(row_IQ, column + 17, calc_mean_dict['Large_MD'])\n",
    "        IQ_data.write(row_IQ, column + 18, calc_mean_dict['Large_LD'])\n",
    "        IQ_data.write(row_IQ, column + 19, calc_mean_dict['Medium_HD'])\n",
    "        IQ_data.write(row_IQ, column + 20, calc_mean_dict['Medium_MD'])\n",
    "        IQ_data.write(row_IQ, column + 21, calc_mean_dict['Medium_LD'])\n",
    "        IQ_data.write(row_IQ, column + 22, calc_mean_dict['Small_HD'])\n",
    "        IQ_data.write(row_IQ, column + 23, calc_mean_dict['Small_MD'])\n",
    "        IQ_data.write(row_IQ, column + 24, calc_mean_dict['Small_LD'])\n",
    "    except:\n",
    "        pass\n",
    "    #IQ_data.write(row_IQ, column + 25, recon_mode)\n",
    "        \n",
    "    row_IQ += 1\n",
    "    \n",
    "    NPS_data.write(0, 0, 'Scan_description')\n",
    "    NPS_data.write(0, 1, 'X / Y')\n",
    "    NPS_data.write(0, 2, 'NPS_data')\n",
    "    \n",
    "    try:\n",
    "        NPS_x_index = 2\n",
    "        for element in quality_output['NPS'][0]:\n",
    "            if NPS_x_index == 2:\n",
    "                NPS_data.write(row_NPS, 0, scan_name)\n",
    "                NPS_data.write(row_NPS, 1, 'x-axis')\n",
    "            NPS_data.write(row_NPS, NPS_x_index, element)\n",
    "            NPS_x_index += 1\n",
    "        row_NPS += 1    \n",
    "        \n",
    "        NPS_y_index = 2\n",
    "        for element in quality_output['NPS'][1]:\n",
    "            if NPS_y_index == 2:\n",
    "                NPS_data.write(row_NPS, 0, scan_name)\n",
    "                NPS_data.write(row_NPS, 1, 'y-axis')\n",
    "            NPS_data.write(row_NPS, NPS_y_index, element)\n",
    "            NPS_y_index += 1\n",
    "        row_NPS += 1 \n",
    "        \n",
    "        MTF_data.write(0, 0, 'Scan_description')\n",
    "        MTF_data.write(0, 1, 'X / Y')\n",
    "        MTF_data.write(0, 2, 'MTF_data')\n",
    "        \n",
    "        MTF_x_index = 2\n",
    "        for element in quality_output['MTF'][0]:\n",
    "            if MTF_x_index == 2:\n",
    "                MTF_data.write(row_MTF, 0, scan_name)\n",
    "                MTF_data.write(row_MTF, 1, 'x-axis')\n",
    "            MTF_data.write(row_MTF, MTF_x_index, element)\n",
    "            MTF_x_index += 1\n",
    "        row_MTF += 1    \n",
    "        \n",
    "        MTF_y_index = 2\n",
    "        for element in quality_output['MTF'][1]:\n",
    "            if MTF_y_index == 2:\n",
    "                MTF_data.write(row_MTF, 0, scan_name)\n",
    "                MTF_data.write(row_MTF, 1, 'y-axis')\n",
    "            MTF_data.write(row_MTF, MTF_y_index, element)\n",
    "            MTF_y_index += 1\n",
    "        row_MTF += 1\n",
    "            \n",
    "        \n",
    "        ESF_data.write(0, 0, 'Scan_description')\n",
    "        ESF_data.write(0, 1, 'X / Y')\n",
    "        ESF_data.write(0, 2, 'ESF_data')\n",
    "        \n",
    "        ESF_x_index = 2\n",
    "        x_val = 0\n",
    "        for element in quality_output['ESF']:\n",
    "            if ESF_x_index == 2:\n",
    "                ESF_data.write(row_ESF, 0, scan_name)\n",
    "                ESF_data.write(row_ESF, 1, 'x-axis')\n",
    "            ESF_data.write(row_ESF, ESF_x_index, x_val)\n",
    "            ESF_x_index += 1\n",
    "            x_val += 1\n",
    "        row_ESF += 1    \n",
    "        \n",
    "        ESF_y_index = 2\n",
    "        for element in quality_output['ESF']:\n",
    "            if ESF_y_index == 2:\n",
    "                ESF_data.write(row_ESF, 0, scan_name)\n",
    "                ESF_data.write(row_ESF, 1, 'y-axis')\n",
    "            ESF_data.write(row_ESF, ESF_y_index, element)\n",
    "            ESF_y_index += 1\n",
    "        row_ESF += 1\n",
    "    \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return row_used, row_NPS, row_MTF, row_IQ, row_ESF\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "294fd2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcification_center(array, calc_indices):\n",
    "    calc_mid = calc_indices[0] + math.ceil((calc_indices[1] - calc_indices[0])/2)\n",
    "    \n",
    "    array_filtered = scipy.signal.medfilt2d(array[:,:,calc_mid], 5)\n",
    "    output = cv2.connectedComponentsWithStats(array_filtered, comp_connect, cv2.CV_32S)\n",
    "    \n",
    "    center_calc = [int(output[3][1][0]), int(output[3][1][1])] \n",
    "    return center_calc\n",
    "\n",
    "\n",
    "def arteries_masked(radius_val = 80):\n",
    "    try:\n",
    "        pixel_size = header.PixelSpacing[0]\n",
    "    except:\n",
    "        FOV = header.ReconstructionDiameter\n",
    "        matrix_size = header.Rows\n",
    "    \n",
    "        pixel_size = FOV / matrix_size\n",
    "    \n",
    "    radius = (radius_val/2) / pixel_size\n",
    "    \n",
    "    Y, X = np.ogrid[:header.Rows, :header.Columns]\n",
    "    dist_from_center = np.sqrt((X - center[1])**2 + (Y-center[0])**2)\n",
    "\n",
    "    mask = dist_from_center <= radius  \n",
    "    masked_array = np.zeros_like(dcm_array)\n",
    "    for index in range(dcm_array.shape[2]):\n",
    "        masked_array[:,:,index] = dcm_array[:,:,index] * mask\n",
    "\n",
    "    return masked_array, mask\n",
    "\n",
    "    \n",
    "def Arteries_calcium_image():\n",
    "    # threshold array according to calcium_threshold \n",
    "    # simultaneously make image binary\n",
    "    array = dcm_array.copy()\n",
    "    array[array < 1.2*calcium_threshold] = 0\n",
    "    array[array > 0] = 1\n",
    "    array = array.astype(dtype = np.uint8)\n",
    "\n",
    "    artery_num_pixels = math.ceil(math.pi * (5/2)**2 / header.PixelSpacing[0]**2)\n",
    "    \n",
    "    # image_kernel = math.ceil(5 / header.PixelSpacing[0])\n",
    "    # if image_kernel % 2 == 0:\n",
    "    #     image_kernel += 1\n",
    "        \n",
    "    image_kernel = 5\n",
    "    \n",
    "    slice_dict =  {}\n",
    "    for idx in range(3,array.shape[2]):\n",
    "        array_filtered = scipy.signal.medfilt2d(array[:,:,idx], image_kernel)\n",
    "        # plt.imshow(array_filtered)\n",
    "        # plt.show()\n",
    "        \n",
    "        output = cv2.connectedComponentsWithStats(array_filtered, comp_connect, cv2.CV_32S)\n",
    "        count_5mm = 0\n",
    "        count_large = 0\n",
    "        count_small = 0\n",
    "            \n",
    "        for index in range(1,output[0]):\n",
    "            tmp_size_calc = output[2][index][4]\n",
    "            if tmp_size_calc < artery_num_pixels * 0.3:\n",
    "                count_small += 1\n",
    "            elif tmp_size_calc > artery_num_pixels * 2.5:\n",
    "                count_large += 1\n",
    "            else:\n",
    "                count_5mm += 1\n",
    "            # if output[2][index][4] in range(int(artery_num_pixels * 4),\\\n",
    "                     # int(artery_num_pixels * 100)):\n",
    "                # count_large += 1\n",
    "                \n",
    "        # print(idx, count_small, count_large, count_5mm)\n",
    "        \n",
    "        if (count_5mm == 1 and count_large == 0 and count_small < 3):\n",
    "            slice_dict[idx] = count_5mm\n",
    "            # plt.imshow(array_filtered)\n",
    "            # plt.title(idx)\n",
    "            # plt.show()\n",
    "            \n",
    "    # print(slice_dict)\n",
    "    \n",
    "    min_key = []\n",
    "    max_key = []\n",
    "    for key in slice_dict.keys():\n",
    "        # print(key, slice_dict[key])\n",
    "        if (key - 1) not in list(slice_dict.keys()):\n",
    "           min_key.append(key) \n",
    "        if (key + 1) not in list(slice_dict.keys()):\n",
    "           max_key.append(key)\n",
    "           \n",
    "    calc1 = [min_key[0], max_key[0]]\n",
    "    calc1.append(calcification_center(array, calc1))\n",
    "    if len(min_key) == 1:\n",
    "        calc2 = [calc1[0] + int(30 / header.SliceThickness), calc1[1] + int(30 / header.SliceThickness)]\n",
    "        calc2.append(calcification_center(array, calc1))\n",
    "    else:\n",
    "        calc2 = [min_key[1], max_key[1]]\n",
    "        calc2.append(calcification_center(array, calc2))\n",
    "        \n",
    "    \n",
    "    # calculate in-plane center of calcifications for mask\n",
    "    \n",
    "    \n",
    "    \n",
    "    # create calcium image\n",
    "    array = dcm_array.copy()\n",
    "    array[array < 1*calcium_threshold] = 0\n",
    "    array[array > 0] = 1\n",
    "    array = array.astype(dtype = np.uint8)\n",
    "    calcium_image = array * dcm_array\n",
    "    \n",
    "    return calcium_image, calc1, calc2\n",
    "\n",
    "\n",
    "def mask_scoring_def(array, calc_min, calc_max):\n",
    "    array[array < calcium_threshold] = 0\n",
    "    array[array > 0] = 1\n",
    "    array = array.astype(dtype = np.uint8)\n",
    "    array_central = array[:,:,int(calc_min + (calc_max - calc_min) / 2)].copy()\n",
    "    \n",
    "    mask_area = np.zeros([array.shape[0], array.shape[1]])\n",
    "    for index in range(calc_min + 2, calc_max - 2):\n",
    "        output = cv2.connectedComponentsWithStats(array[:,:,index], comp_connect, cv2.CV_32S)\n",
    "        \n",
    "        for index_output in range(1,output[0]):\n",
    "            area = output[2][index_output][4] * header.PixelSpacing[0]**2\n",
    "            \n",
    "            min_area = min_area_det(header.Manufacturer)\n",
    "            \n",
    "            if area < min_area:\n",
    "                output[1][output[1] == index_output] = 0\n",
    "                \n",
    "        mask_area = np.add(mask_area, output[1])\n",
    "            \n",
    "    mask_area[mask_area != 0] = 1\n",
    "    mask_area = array.astype(dtype = np.uint8)\n",
    "    mask_area = np.max(mask_area, 2)\n",
    "    \n",
    "    output = cv2.connectedComponentsWithStats(mask_area, comp_connect, cv2.CV_32S)\n",
    "    \n",
    "    pixel_list = []\n",
    "    for index in range(1,output[0]):\n",
    "        pixel_list.append(output[2][index][4])\n",
    "\n",
    "    highest_pixelcount = pixel_list.index(max(pixel_list)) + 1\n",
    "    \n",
    "    mask_area = create_circular_mask(array.shape[0], array.shape[1], output[3][highest_pixelcount],\\\n",
    "                                     5 / header.PixelSpacing[0])\n",
    "    \n",
    "    output = cv2.connectedComponentsWithStats(array_central, comp_connect, cv2.CV_32S)\n",
    "    pixel_list = []\n",
    "    for index in range(1,output[0]):\n",
    "        pixel_list.append(output[2][index][4])\n",
    "\n",
    "    highest_pixelcount = pixel_list.index(max(pixel_list)) + 1\n",
    "    output[1][output[1] != highest_pixelcount] = 0\n",
    "    \n",
    "    mask_area = np.add(mask_area, output[1])\n",
    "    mask_area[mask_area != 0] = 1\n",
    "    \n",
    "    return mask_area\n",
    "\n",
    "\n",
    "def arteries_scoring(calc_index):\n",
    "    # Actual scoring for arteries insert per calcification         \n",
    "    calc_min = calc_index[0] - 2\n",
    "    calc_max = calc_index[1] + 2\n",
    "    calc_array = dcm_array[:,:,calc_min:calc_max]\n",
    "    calcium_calc_array = calcium_image[:,:,calc_min:calc_max]\n",
    "    \n",
    "    calc_array_binary = calc_array.copy()\n",
    "    calc_array_binary[calc_array_binary < calcium_threshold] = 0\n",
    "    calc_array_binary[calc_array_binary > 0] = 1\n",
    "    calc_array_binary = calc_array_binary.astype(dtype = np.uint8)\n",
    "    \n",
    "    mask_scoring = mask_scoring_def(calcium_image.copy(), calc_min, calc_max)\n",
    "\n",
    "    if (Volume_score_calc and (header.Manufacturer == 'SIEMENS' or header.Manufacturer == 'Literature')): \n",
    "        calc_int_min = int(calc_min * int_factor + int_factor / 2)\n",
    "        calc_int_max = int(calc_max * int_factor - int_factor / 2)\n",
    "        calc_array_int = int_dcm_array[:,:,calc_int_min:calc_int_max]\n",
    "        \n",
    "        calc_array_int_binary = calc_array_int.copy()\n",
    "        calc_array_int_binary[calc_array_int_binary < calcium_threshold] = 0\n",
    "        calc_array_int_binary[calc_array_int_binary > 0] = 1\n",
    "        calc_array_int_binary = calc_array_int_binary.astype(dtype = np.uint8)\n",
    "        \n",
    "        # Volume score calculation\n",
    "        Volume_score = 0\n",
    "        for slice_index in range(calc_array_int.shape[2]):\n",
    "            output = cv2.connectedComponentsWithStats(calc_array_int_binary[:,:,slice_index],\\\n",
    "                                                          comp_connect, cv2.CV_32S)\n",
    "    \n",
    "            for slice_index2 in range(1,output[0]):\n",
    "                coordinates = int(output[3][slice_index2][1]), int(output[3][slice_index2][0])\n",
    "                area = output[2][slice_index2][4] * int_header.PixelSpacing[0]**2\n",
    "                \n",
    "                min_area = min_area_det(header.Manufacturer)\n",
    "                \n",
    "                if area > min_area:\n",
    "                    VS = area * int_header.SliceThickness\n",
    "                    if mask_scoring[coordinates] != False:\n",
    "                        Volume_score += VS\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pass\n",
    "    else:\n",
    "        Volume_score = 0\n",
    "          \n",
    "    # Agatston and Mass score calculation\n",
    "    Agatston_score = 0\n",
    "    Mass_score = 0\n",
    "    num_voxels = 0\n",
    "    for slice_index in range(calc_array.shape[2]):\n",
    "        output = cv2.connectedComponentsWithStats(calc_array_binary[:,:,slice_index],\\\n",
    "                                                      comp_connect, cv2.CV_32S)\n",
    "            \n",
    "        for slice_index2 in range(1,output[0]):\n",
    "            coordinates = int(output[3][slice_index2][1]), int(output[3][slice_index2][0])\n",
    "            area = output[2][slice_index2][4] * header.PixelSpacing[0]**2\n",
    "            num_vox_calc = output[2][slice_index2][4]\n",
    "            \n",
    "            min_area = min_area_det(header.Manufacturer)\n",
    "                    \n",
    "            if area > min_area:\n",
    "                if mask_scoring[coordinates] != False:\n",
    "                    AS_weight = AS_weight_calc(mask_scoring, calcium_calc_array[:,:,slice_index])\n",
    "                    Agatston_score += AS_weight * area\n",
    "                    \n",
    "                    MS = area * header.SliceThickness * mass_mean_def(mask_scoring * calcium_calc_array[:,:,slice_index])\n",
    "                    Mass_score += MS\n",
    "                    \n",
    "                    num_voxels += num_vox_calc\n",
    "                else:\n",
    "                    pass\n",
    "            else:\n",
    "                pass  \n",
    "\n",
    "    if (header.Manufacturer == 'PHILIPS' or header.Manufacturer == 'CANON'):\n",
    "        Mass_score = 0\n",
    "        Volume_score = 0\n",
    "        num_voxels = 0\n",
    "        \n",
    "        min_area = min_area_det(header.Manufacturer)\n",
    "        \n",
    "        calc_array_binary = calc_array.copy()\n",
    "        if header.Manufacturer == 'PHILIPS':\n",
    "            calc_array_binary[calc_array_binary < Philips_mass_score_threshold] = 0\n",
    "        else:\n",
    "            calc_array_binary[calc_array_binary < calcium_threshold] = 0\n",
    "        calc_array_binary[calc_array_binary > 0] = 1\n",
    "        calc_array_binary = calc_array_binary.astype(dtype = np.uint8)\n",
    "        \n",
    "        # Volume and Mass score calculation\n",
    "        for slice_index in range(calc_array.shape[2]):\n",
    "            output = cv2.connectedComponentsWithStats(calc_array_binary[:,:,slice_index],\\\n",
    "                                                          comp_connect, cv2.CV_32S)\n",
    "            \n",
    "            for slice_index2 in range(1,output[0]):\n",
    "                coordinates = int(output[3][slice_index2][1]), int(output[3][slice_index2][0])\n",
    "                area = output[2][slice_index2][4] * header.PixelSpacing[0]**2 \n",
    "                num_vox_calc = output[2][slice_index2][4]\n",
    "                \n",
    "                mask_mean_mass = output[1].copy()\n",
    "                mask_mean_mass[mask_mean_mass != slice_index2] = 0\n",
    "                mask_mean_mass[mask_mean_mass != 0] = 1\n",
    "\n",
    "                if area > min_area:\n",
    "                    MS = area * header.SliceThickness * mass_mean_def(mask_mean_mass * calcium_calc_array[:,:,slice_index])\n",
    "                    VS = area * header.SliceThickness\n",
    "                    \n",
    "                    if mask_scoring[coordinates] != False:\n",
    "                        MS = area * header.SliceThickness * mass_mean_def(mask_scoring * calcium_calc_array[:,:,slice_index])\n",
    "                        VS = area * header.SliceThickness\n",
    "                        \n",
    "                        Mass_score += MS \n",
    "                        Volume_score += VS\n",
    "                        \n",
    "                        num_voxels += num_vox_calc\n",
    "                else:\n",
    "                    pass      \n",
    "            \n",
    "    Volume_score = round(Volume_score, 5)\n",
    "    Mass_score = round(Mass_score * mass_cal_factor, 5)\n",
    "    Agatston_score = round(Agatston_score * header.SliceThickness / 3, 5)\n",
    "    \n",
    "    scores = [Agatston_score, Mass_score, Volume_score]\n",
    "\n",
    "    return scores, num_voxels, mask_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6daffbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_Arteries_to_excel(row_used, row_NPS, row_IQ):\n",
    "    used_data.write(0, 0, 'Scan_description')\n",
    "    used_data.write(0, 1, 'AS_1')\n",
    "    used_data.write(0, 2, 'MS_1')\n",
    "    used_data.write(0, 3, 'VS_1')\n",
    "    used_data.write(0, 4, 'AS_2')\n",
    "    used_data.write(0, 5, 'MS_2')\n",
    "    used_data.write(0, 6, 'VS_2')\n",
    "    used_data.write(0, 7, 'Mass calibration factor')\n",
    "    used_data.write(0, 8, 'mAs')\n",
    "    used_data.write(0, 9, 'kVp')\n",
    "    used_data.write(0, 10, 'Time')\n",
    "    used_data.write(0, 11, 'Recon Kernel')\n",
    "    used_data.write(0, 12, 'CTDIvol')\n",
    "    used_data.write(0, 13, 'Calcium Threshold')\n",
    "    used_data.write(0, 14, 'Accnr')\n",
    "    used_data.write(0, 15, 'SliceThickness')\n",
    "    used_data.write(0, 16, 'Increment')\n",
    "    used_data.write(0, 17, 'DCM_name')\n",
    "    \n",
    "    \n",
    "    scan_name = dcm_name.rsplit(root_path)[1][1:]\n",
    "    scan_name = dcm_name.rsplit('\\\\')[len(dcm_name.rsplit('\\\\'))-1]\n",
    "    \n",
    "    mAs = str(header.XRayTubeCurrent)\n",
    "    PID = header.PatientID\n",
    "    kVp = str(header.KVP)\n",
    "    acq_time = str(header.AcquisitionTime)\n",
    "    scan_name = PID + '_' + mAs + '_' + kVp + '_' + acq_time\n",
    "    scan_name = PID\n",
    "    \n",
    "    used_data.write(row_used, column, scan_name)\n",
    "    used_data.write(row_used, column + 1, scores_calc1[0])\n",
    "    used_data.write(row_used, column + 2, scores_calc1[1])\n",
    "    used_data.write(row_used, column + 3, scores_calc1[2])\n",
    "    used_data.write(row_used, column + 4, scores_calc2[0])\n",
    "    used_data.write(row_used, column + 5, scores_calc2[1])\n",
    "    used_data.write(row_used, column + 6, scores_calc2[2])\n",
    "    used_data.write(row_used, column + 7, mass_cal_factor * 1000)\n",
    "    used_data.write(row_used, column + 8, header.XRayTubeCurrent)\n",
    "    used_data.write(row_used, column + 9, header.KVP)\n",
    "    used_data.write(row_used, column + 10, header.AcquisitionTime)\n",
    "    try:\n",
    "        used_data.write(row_used, column + 11, header.ConvolutionKernel)\n",
    "    except:\n",
    "        used_data.write(row_used, column + 11, header.ConvolutionKernel[0])\n",
    "    used_data.write(row_used, column + 12, header.CTDIvol)\n",
    "    used_data.write(row_used, column + 13, calcium_threshold)\n",
    "    used_data.write(row_used, column + 14, header.AccessionNumber)\n",
    "    used_data.write(row_used, column + 15, slice_thick_ori)\n",
    "    try:\n",
    "        used_data.write(row_used, column + 16, header.SpacingBetweenSlices)\n",
    "    except:\n",
    "        try:\n",
    "            used_data.write(row_used, column + 16, header.SliceThickness)\n",
    "        except:\n",
    "            pass\n",
    "    used_data.write(row_used, column + 17, dcm_name)\n",
    "    try:\n",
    "        used_data.write(row_used, column + 14, str(header[0x7005,0x100b].value))\n",
    "        if str(header[0x7005,0x100b].value) == 'ORG':\n",
    "            used_data.write(row_used, column + 14, \"FBP\")    \n",
    "        if str(header[0x7005,0x1092].value) != \"volumeXact+\":\n",
    "            used_data.write(row_used, column + 14, str(header[0x7005,0x1092].value))\n",
    "    except: \n",
    "        pass\n",
    "\n",
    "        \n",
    "    \n",
    "    row_used += 1\n",
    "    \n",
    "    IQ_data.write(0, 0, 'Phantom')\n",
    "    IQ_data.write(0, 1, 'Scan_description')\n",
    "    IQ_data.write(0, 2, 'Background mean HU')\n",
    "    IQ_data.write(0, 3, 'Background SD')\n",
    "    IQ_data.write(0, 4, 'Background AS')\n",
    "    IQ_data.write(0, 5, 'NTD')\n",
    "    IQ_data.write(0, 6, 'NPS peak')\n",
    "    IQ_data.write(0, 7, 'Mean_calc1')\n",
    "    IQ_data.write(0, 8, 'SNR_calc1')\n",
    "    IQ_data.write(0, 9, 'CNR_calc1')\n",
    "    IQ_data.write(0, 10, 'Number_voxels_calc1')\n",
    "    IQ_data.write(0, 11, 'Mean_calc2')\n",
    "    IQ_data.write(0, 12, 'SNR_calc2')\n",
    "    IQ_data.write(0, 13, 'CNR_calc2')\n",
    "    IQ_data.write(0, 14, 'Number_voxels_calc2')\n",
    "    \n",
    "    IQ_data.write(row_IQ, column, phantom)\n",
    "    IQ_data.write(row_IQ, column + 1, scan_name)\n",
    "    IQ_data.write(row_IQ, column + 2, quality_output['mean'])\n",
    "    IQ_data.write(row_IQ, column + 3, quality_output['SD'])\n",
    "    IQ_data.write(row_IQ, column + 4, quality_output['AS'])\n",
    "    #IQ_data.write(row_IQ, column + 5, quality_output['NTD'])\n",
    "    #IQ_data.write(row_IQ, column + 6, quality_output['NPS_peak'])\n",
    "    IQ_data.write(row_IQ, column + 7, quality_output['mean_calc1'])\n",
    "    IQ_data.write(row_IQ, column + 8, quality_output['SNR_calc1'])\n",
    "    IQ_data.write(row_IQ, column + 9, quality_output['CNR_calc1'])\n",
    "    IQ_data.write(row_IQ, column + 10, quality_output['num_vox_calc1'])\n",
    "    IQ_data.write(row_IQ, column + 11, quality_output['mean_calc2'])\n",
    "    IQ_data.write(row_IQ, column + 12, quality_output['SNR_calc2'])\n",
    "    IQ_data.write(row_IQ, column + 13, quality_output['CNR_calc2'])\n",
    "    IQ_data.write(row_IQ, column + 14, quality_output['num_vox_calc2'])\n",
    "    \n",
    "    row_IQ += 1\n",
    "    \n",
    "    # NPS_data.write(0, 0, 'Scan_description')\n",
    "    # NPS_data.write(0, 1, 'X / Y')\n",
    "    # NPS_data.write(0, 2, 'NPS_data')\n",
    "    \n",
    "    # NPS_x_index = 2\n",
    "    # for element in quality_output['NPS'][0]:\n",
    "    #     if NPS_x_index == 2:\n",
    "    #         NPS_data.write(row_NPS, 0, scan_name)\n",
    "    #         NPS_data.write(row_NPS, 1, 'x-axis')\n",
    "    #     NPS_data.write(row_NPS, NPS_x_index, element)\n",
    "    #     NPS_x_index += 1\n",
    "    # row_NPS += 1    \n",
    "    \n",
    "    # NPS_y_index = 2\n",
    "    # for element in quality_output['NPS'][1]:\n",
    "    #     if NPS_y_index == 2:\n",
    "    #         NPS_data.write(row_NPS, 0, scan_name)\n",
    "    #         NPS_data.write(row_NPS, 1, 'y-axis')\n",
    "    #     NPS_data.write(row_NPS, NPS_y_index, element)\n",
    "    #     NPS_y_index += 1\n",
    "    # row_NPS += 1 \n",
    "    \n",
    "    return row_used, row_NPS, row_IQ\n",
    "\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "#### Actual script\n",
    "###############################################################################\n",
    "###############################################################################\n",
    "\n",
    "def dcm_interpolation_slices(array, input_slice_thickness):\n",
    "    # define interpolation method via order:\n",
    "    array_int = array.copy()\n",
    "    int_header = copy.deepcopy(header)\n",
    "    \n",
    "    int_header.SliceThickness = input_slice_thickness\n",
    "    \n",
    "    # actual interpolation\n",
    "    steps = [header.Rows + 1, header.Columns + 1, header.SliceThickness]    # original step sizes\n",
    "    x, y, z = [steps[k] * np.arange(array_int.shape[k]) for k in range(3)]  # original grid\n",
    "    f = rgi((x, y, z), array_int)    # interpolator\n",
    "    \n",
    "    dx, dy, dz = header.Rows, header.Columns,  input_slice_thickness    # new step sizes\n",
    "    new_grid = np.mgrid[0:x[-1]:dx, 0:y[-1]:dy, 0:z[-1]:dz]   # new grid\n",
    "    new_grid = np.moveaxis(new_grid, (0, 1, 2, 3), (3, 0, 1, 2))  # reorder axes for evaluation\n",
    "    new_values = f(new_grid)\n",
    "\n",
    "    return int_header, new_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b16f42a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0e5925",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b964e25d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3189d55f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f7992a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory =  Z:\\Phantoms\\CCI Phantom Scans\\FQM_CCI_scans\\Canon_Aquilion_One_Vision\\Lagre_rep1\n",
      "Used insert =  CCI\n",
      "Used threshold =  default\n",
      "Used scoring method =  default\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "FileCreateError",
     "evalue": "[Errno 2] No such file or directory: 'Z:\\\\Phantoms\\\\CCI Phantom Scans\\\\FQM_CCI_scans\\\\Canon_Aquilion_One_Vision\\\\Lagre_rep1/Results_CCI_2021-10-29default.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/xlsxwriter/workbook.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/xlsxwriter/workbook.py\u001b[0m in \u001b[0;36m_store_workbook\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/xlsxwriter/workbook.py\u001b[0m in \u001b[0;36m_store_workbook\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    655\u001b[0m             xlsx_file = ZipFile(self.filename, \"w\", compression=ZIP_DEFLATED,\n\u001b[0;32m--> 656\u001b[0;31m                                 allowZip64=self.allow_zip64)\n\u001b[0m\u001b[1;32m    657\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64)\u001b[0m\n\u001b[1;32m   1112\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Z:\\\\Phantoms\\\\CCI Phantom Scans\\\\FQM_CCI_scans\\\\Canon_Aquilion_One_Vision\\\\Lagre_rep1/Results_CCI_2021-10-29default.xlsx'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileCreateError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-c85acf7722e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0mrow_not_used\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/srv/conda/envs/notebook/lib/python3.6/site-packages/xlsxwriter/workbook.py\u001b[0m in \u001b[0;36mclose\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_store_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mIOError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 325\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mFileCreateError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    326\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLargeZipFile\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m                 raise FileSizeError(\"Filesize would require ZIP64 extensions. \"\n",
      "\u001b[0;31mFileCreateError\u001b[0m: [Errno 2] No such file or directory: 'Z:\\\\Phantoms\\\\CCI Phantom Scans\\\\FQM_CCI_scans\\\\Canon_Aquilion_One_Vision\\\\Lagre_rep1/Results_CCI_2021-10-29default.xlsx'"
     ]
    }
   ],
   "source": [
    "root_path = r'Z:\\Phantoms\\CCI Phantom Scans\\FQM_CCI_scans\\Canon_Aquilion_One_Vision\\Lagre_rep1'\n",
    "\n",
    "output_path = root_path #r'D:\\Data_UMCU\\RUMC_DLR\\CASCORE_CCI'\n",
    "\n",
    "print('Directory = ', root_path)\n",
    "\n",
    "try:\n",
    "    repetition = root_path.split(\"repetition\",1)[1]\n",
    "except:\n",
    "    repetition = 0\n",
    "    pass\n",
    "\n",
    "# Definition of phantom insert (CCI / D100 / arteries)\n",
    "phantom = 'CCI'\n",
    "QRM_phantom = 'thorax'\n",
    "print('Used insert = ', phantom)\n",
    "\n",
    "# Definition of parameter for connected components: 4 or 8\n",
    "comp_connect = 4    \n",
    "\n",
    "# Definition if default 130HU or other threshold should be used: default or kVp_adjusted or monoE\n",
    "calcium_threshold_declaration = 'default'\n",
    "Volume_score_calc = True\n",
    "Philips_mass_score_threshold = 130#int(100/0.88)\n",
    "print('Used threshold = ', calcium_threshold_declaration)\n",
    "\n",
    "# Definition of used scoring method: Philips / Siemens / Canon / GE / literature / default\n",
    "scoring_method = 'default'\n",
    "#scoring_method = 'Canon'\n",
    "print('Used scoring method = ', scoring_method)\n",
    "\n",
    "# create excel file in root_folder to write results to\n",
    "wb = xlsxwriter.Workbook(os.path.join(output_path, 'Results_' + phantom + '_' + str(date.today()) + scoring_method + '.xlsx'))\n",
    "used_data = wb.add_worksheet('Used_data')\n",
    "IQ_data = wb.add_worksheet('IQ_data')\n",
    "NPS_data = wb.add_worksheet('NPS')\n",
    "MTF_data = wb.add_worksheet('MTF')\n",
    "ESF_data = wb.add_worksheet('ESF')\n",
    "not_used_sheet = wb.add_worksheet('Unused_data')\n",
    "row_not_used = 0\n",
    "row_used = 1\n",
    "row_NPS = 1\n",
    "row_MTF = 1\n",
    "row_IQ = 1\n",
    "row_ESF = 1\n",
    "not_used_dir = []\n",
    "\n",
    "\n",
    "\n",
    "# Create list of paths in root_path where DCM files exist \n",
    "dcm_path_list = dcm_list_builder(root_path) \n",
    "\n",
    "# For each path in dcm_path_list parse data\n",
    "for idx in tqdm(range(len(dcm_path_list))):\n",
    "    gc.collect()\n",
    "    dcm_name = dcm_path_list[idx]\n",
    "    # print(dcm_name)\n",
    "    try:\n",
    "        header, dcm_array, slice_thick_ori = dcm_reader(dcm_path_list[idx])\n",
    "        dcm_array_ori = dcm_array.copy()\n",
    "        \n",
    "        # set threshold, which is used for analysis, default is 130HU\n",
    "        calcium_threshold = threshold_def(calcium_threshold_declaration)\n",
    "\n",
    "        # set scoring method, used for CCS-scoring as defined by scoring_method:\n",
    "        header.Manufacturer = scoring_method_selector()\n",
    "\n",
    "        # mask insert of dcm_array\n",
    "        dcm_array, center, mask = dcm_masked(array_used = dcm_array,\\\n",
    "                                                     slice_used_center = int(dcm_array.shape[2]/2))\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "#### CCI part\n",
    "###############################################################################\n",
    "        if phantom == 'CCI':\n",
    "            # definitions for excel output\n",
    "            column = 0\n",
    "            \n",
    "            # get slice with calcifications, thresholded image and quality slice\n",
    "            calcium_image, CCI_slice, quality_slice, cal_rod_slice, flipped = CCI_calcium_image()\n",
    "            \n",
    "            # actual calcium scoring for CCI phantom\n",
    "            calc_size_density_VS_AS_MS, center, mass_cal_factor,\\\n",
    "                calc_mean_dict, angle_0_200HA, water_rod, SNR_dict, CCI_mask_BAS =\\\n",
    "                            CCI_scoring(print_plot = False)\n",
    "            \n",
    "            # calculate image quality information\n",
    "            quality_output = calcium_quality()\n",
    "            \n",
    "            Cal_rod_AS, Cal_rod_mean = Measurement_calrod(calcium_image[:,:,cal_rod_slice].copy()) \n",
    "            # Calculate MTF for 200mgHA insert\n",
    "            \n",
    "            quality_output['MTF'], quality_output['MTF0.5'], quality_output['ESF'] = MTF_200mgHA(plot_MTF = False)\n",
    "\n",
    "            # Write results to excel\n",
    "            row_used, row_NPS, row_MTF, row_IQ, row_ESF =\\\n",
    "                        write_CCI_to_excel(row_used, row_NPS, row_MTF, row_IQ, row_ESF)\n",
    "                        \n",
    "###############################################################################\n",
    "#### D100 part\n",
    "###############################################################################\n",
    "                   \n",
    "\n",
    "###############################################################################\n",
    "#### Arteries part\n",
    "###############################################################################\n",
    "        elif phantom == 'arteries':\n",
    "\n",
    "        \n",
    "            # definitions for excel output\n",
    "            column = 0\n",
    "            int_factor = header.SliceThickness / header.PixelSpacing[0]\n",
    "\n",
    "            # decrease insert size further to 80 mm; recalculate interpolated matrix\n",
    "            dcm_array, mask = arteries_masked()\n",
    "            if (Volume_score_calc and (header.Manufacturer == 'SIEMENS' or header.Manufacturer == 'Literature')):\n",
    "                int_header, int_dcm_array = dcm_interpolation(dcm_array)\n",
    "            \n",
    "            # create calcium image and get index of both calcifications\n",
    "            calcium_image, calc1, calc2 = Arteries_calcium_image()\n",
    "            \n",
    "            # calculate CCS for artery\n",
    "            mass_cal_factor = 0.001\n",
    "            scores_calc1, num_vox_1, mask_scoring = arteries_scoring(calc1)\n",
    "            scores_calc2, num_vox_2, _ = arteries_scoring(calc2)\n",
    "            \n",
    "            quality_output = calcium_quality()\n",
    "            quality_output['num_vox_calc1'] = num_vox_1\n",
    "            quality_output['num_vox_calc2'] = num_vox_2\n",
    "            \n",
    "            row_used, row_NPS, row_IQ = write_Arteries_to_excel(row_used, row_NPS, row_IQ)\n",
    "\n",
    "            \n",
    "    except:\n",
    "        not_used_sheet.write(row_not_used, 0, dcm_name)\n",
    "        not_used_dir.append(dcm_name)\n",
    "        #print(dcm_name)\n",
    "        row_not_used += 1\n",
    "                   \n",
    "wb.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2782dff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41964c11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec44214",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decaec39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c0cad2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b323a05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6919380f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
